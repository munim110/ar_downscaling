{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uhfEGt4IoKb",
        "outputId": "1bcad5f8-7703-49e6-9d9f-66773743b231"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 Training Stage 2 Diagnostic Network on device: cuda\n",
            "--- Generating Stage 1 Predictions for Diagnostic Network Training ---\n",
            "Processing 'train' split...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating Stage 1 preds for train: 100%|██████████| 1200/1200 [04:58<00:00,  4.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing 'val' split...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating Stage 1 preds for val: 100%|██████████| 150/150 [00:20<00:00,  7.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Stage 1 Prediction Generation Complete ---\n",
            "Loaded 1200 Stage 1 predictions for 'train' split.\n",
            "Loaded 150 Stage 1 predictions for 'val' split.\n",
            "\n",
            "Starting Stage 2 Diagnostic training for 30 epochs...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:52<00:00,  2.87it/s, loss=2.2938]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30 | Validation CSI @ 220.0K: 0.1578\n",
            "✅ New best CSI! Model saved to /content/drive/My Drive/AR_Downscaling/final_diagnostic_model/best_diagnostic_model.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:20<00:00,  7.48it/s, loss=1.8196]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/30 | Validation CSI @ 220.0K: 0.1571\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:20<00:00,  7.47it/s, loss=2.6381]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/30 | Validation CSI @ 220.0K: 0.1557\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:19<00:00,  7.52it/s, loss=2.1981]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/30 | Validation CSI @ 220.0K: 0.1541\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:19<00:00,  7.52it/s, loss=2.5044]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/30 | Validation CSI @ 220.0K: 0.1584\n",
            "✅ New best CSI! Model saved to /content/drive/My Drive/AR_Downscaling/final_diagnostic_model/best_diagnostic_model.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:19<00:00,  7.52it/s, loss=2.1244]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/30 | Validation CSI @ 220.0K: 0.1553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:20<00:00,  7.50it/s, loss=1.9735]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/30 | Validation CSI @ 220.0K: 0.1512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:20<00:00,  7.49it/s, loss=2.3915]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/30 | Validation CSI @ 220.0K: 0.1509\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:19<00:00,  7.50it/s, loss=2.2511]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/30 | Validation CSI @ 220.0K: 0.1512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:19<00:00,  7.50it/s, loss=2.7644]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/30 | Validation CSI @ 220.0K: 0.1370\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:19<00:00,  7.50it/s, loss=3.0110]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/30 | Validation CSI @ 220.0K: 0.1528\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:19<00:00,  7.50it/s, loss=2.1704]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/30 | Validation CSI @ 220.0K: 0.1455\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:20<00:00,  7.50it/s, loss=1.5507]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/30 | Validation CSI @ 220.0K: 0.1557\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:19<00:00,  7.50it/s, loss=3.2203]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/30 | Validation CSI @ 220.0K: 0.1653\n",
            "✅ New best CSI! Model saved to /content/drive/My Drive/AR_Downscaling/final_diagnostic_model/best_diagnostic_model.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:20<00:00,  7.50it/s, loss=2.3269]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/30 | Validation CSI @ 220.0K: 0.1464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:19<00:00,  7.50it/s, loss=2.1238]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/30 | Validation CSI @ 220.0K: 0.1515\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:19<00:00,  7.50it/s, loss=1.7916]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/30 | Validation CSI @ 220.0K: 0.1562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:20<00:00,  7.49it/s, loss=2.0061]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/30 | Validation CSI @ 220.0K: 0.1533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:20<00:00,  7.49it/s, loss=2.1148]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/30 | Validation CSI @ 220.0K: 0.1495\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:20<00:00,  7.49it/s, loss=1.8967]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/30 | Validation CSI @ 220.0K: 0.1597\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:20<00:00,  7.50it/s, loss=1.9060]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/30 | Validation CSI @ 220.0K: 0.1464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:20<00:00,  7.50it/s, loss=2.3870]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/30 | Validation CSI @ 220.0K: 0.1487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:19<00:00,  7.51it/s, loss=2.2977]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/30 | Validation CSI @ 220.0K: 0.1535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:19<00:00,  7.50it/s, loss=2.7834]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/30 | Validation CSI @ 220.0K: 0.1482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:20<00:00,  7.50it/s, loss=2.7248]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/30 | Validation CSI @ 220.0K: 0.1496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 26/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:20<00:00,  7.48it/s, loss=2.4848]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26/30 | Validation CSI @ 220.0K: 0.1494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:19<00:00,  7.50it/s, loss=2.0123]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27/30 | Validation CSI @ 220.0K: 0.1583\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 28/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:20<00:00,  7.50it/s, loss=1.9178]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28/30 | Validation CSI @ 220.0K: 0.1492\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 29/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:19<00:00,  7.50it/s, loss=2.6102]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29/30 | Validation CSI @ 220.0K: 0.1400\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 30/30 [Diagnostic Train]: 100%|██████████| 150/150 [00:19<00:00,  7.50it/s, loss=1.7906]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30/30 | Validation CSI @ 220.0K: 0.1556\n",
            "\n",
            "🎉 Diagnostic Network training complete! Best CSI achieved: 0.1653\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# This script trains the Stage 2 \"Diagnostic Network\" for the decoupled\n",
        "# \"Forecast and Diagnose\" pipeline.\n",
        "#\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import joblib\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import gc\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "PROJECT_PATH = Path('/content/drive/My Drive/AR_Downscaling')\n",
        "DATA_DIR = PROJECT_PATH / 'final_dataset_multi_variable'\n",
        "ABLATION_MODEL_DIR = PROJECT_PATH / 'ablation_study_models'\n",
        "OUTPUT_DIR = PROJECT_PATH / 'final_diagnostic_model'\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# --- Path to the Stage 1 \"Forecast Engine\" ---\n",
        "STAGE_1_MODEL_PATH = ABLATION_MODEL_DIR / 'ablation_remove_IVT.pt'\n",
        "\n",
        "# --- Training Hyperparameters ---\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 8\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "# --- Loss Function Weights ---\n",
        "LAMBDA_BCE = 1.0\n",
        "LAMBDA_DICE = 3.0 # Heavier weight on spatial overlap\n",
        "\n",
        "# --- Model & Data Configuration ---\n",
        "ALL_VARIABLES = ['IVT', 'T500', 'T850', 'RH700', 'W500']\n",
        "VARIABLES_TO_USE = ['T500', 'T850', 'RH700', 'W500']\n",
        "VARIABLE_INDICES = [ALL_VARIABLES.index(v) for v in VARIABLES_TO_USE]\n",
        "INPUT_CHANNELS = len(VARIABLE_INDICES)\n",
        "DIAGNOSTIC_THRESHOLD_K = 220.0\n",
        "\n",
        "# --- 2. DATASET FOR DIAGNOSTIC NETWORK ---\n",
        "class DiagnosticDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A dataset where the input is the prediction from the Stage 1 model\n",
        "    and the target is a binary mask of the severe storm cores.\n",
        "    \"\"\"\n",
        "    def __init__(self, data_dir: Path, split: str, stage1_predictions_dir: Path):\n",
        "        self.split_dir = data_dir / split\n",
        "        self.stage1_dir = stage1_predictions_dir / split\n",
        "        self.stats = joblib.load(data_dir / 'normalization_stats_multi_variable.joblib')\n",
        "\n",
        "        self.stage1_files = sorted(list(self.stage1_dir.glob('*.npy')))\n",
        "        self.target_files = [self.split_dir / f\"{p.stem.replace('pred_', '')}_target.npy\" for p in self.stage1_files]\n",
        "\n",
        "        print(f\"Loaded {len(self.stage1_files)} Stage 1 predictions for '{split}' split.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.stage1_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Input is the Stage 1 prediction (already normalized)\n",
        "        input_data = np.load(self.stage1_files[idx]).astype(np.float32)\n",
        "\n",
        "        # Target is the real ground truth, which we convert to a binary mask\n",
        "        target_data = np.load(self.target_files[idx]).astype(np.float32)\n",
        "        target_mask = (target_data <= DIAGNOSTIC_THRESHOLD_K).astype(np.float32)\n",
        "\n",
        "        return torch.from_numpy(input_data).unsqueeze(0), torch.from_numpy(target_mask).unsqueeze(0)\n",
        "\n",
        "# --- 3. MODEL ARCHITECTURES ---\n",
        "class SimplifiedAttention(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.channel_att = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Conv2d(channels, channels // 16, 1), nn.ReLU(inplace=True), nn.Conv2d(channels // 16, channels, 1), nn.Sigmoid())\n",
        "        self.spatial_att = nn.Sequential(nn.Conv2d(channels, 1, 7, padding=3), nn.Sigmoid())\n",
        "    def forward(self, x):\n",
        "        ch_att = self.channel_att(x); x = x * ch_att; sp_att = self.spatial_att(x); x = x * sp_att\n",
        "        return x\n",
        "\n",
        "class FlexibleAblationModel(nn.Module): # Stage 1 Model\n",
        "    def __init__(self, input_channels, base_channels=64, depth=4, use_attention=True):\n",
        "        super().__init__()\n",
        "        self.use_attention, self.depth = use_attention, depth\n",
        "        self.channels = [base_channels * min(2**i, 8) for i in range(depth)]\n",
        "        self.encoders, self.downsamplers = nn.ModuleList(), nn.ModuleList()\n",
        "        in_ch = input_channels\n",
        "        for i, out_ch in enumerate(self.channels):\n",
        "            self.encoders.append(self._conv_block(in_ch, out_ch))\n",
        "            if i < len(self.channels) - 1: self.downsamplers.append(nn.Conv2d(out_ch, out_ch, 3, stride=2, padding=1))\n",
        "            in_ch = out_ch\n",
        "        bottleneck_ch = self.channels[-1]\n",
        "        self.bottleneck = self._conv_block(self.channels[-1], bottleneck_ch)\n",
        "        if self.use_attention: self.attention = SimplifiedAttention(bottleneck_ch)\n",
        "        self.upsamplers, self.decoders = nn.ModuleList(), nn.ModuleList()\n",
        "        for i in range(depth - 1, -1, -1):\n",
        "            in_ch = bottleneck_ch if i == depth - 1 else self.channels[i+1]\n",
        "            out_ch = self.channels[i]\n",
        "            self.upsamplers.append(nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2))\n",
        "            self.decoders.append(self._conv_block(out_ch * 2, out_ch))\n",
        "        self.final_conv = nn.Sequential(nn.Conv2d(self.channels[0], self.channels[0] // 2, 3, padding=1), nn.BatchNorm2d(self.channels[0] // 2), nn.ReLU(inplace=True), nn.Conv2d(self.channels[0] // 2, 1, 1))\n",
        "    def _conv_block(self, in_ch, out_ch): return nn.Sequential(nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True), nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True))\n",
        "    def forward(self, x):\n",
        "        skips = []\n",
        "        for i in range(len(self.encoders)):\n",
        "            x = self.encoders[i](x); skips.append(x)\n",
        "            if i < len(self.downsamplers): x = self.downsamplers[i](x)\n",
        "        x = self.bottleneck(x)\n",
        "        if self.use_attention: x = self.attention(x)\n",
        "        for i, (up, dec) in enumerate(zip(self.upsamplers, self.decoders)):\n",
        "            x = up(x); skip = skips[len(skips) - 1 - i]\n",
        "            if x.shape[-2:] != skip.shape[-2:]: x = F.interpolate(x, size=skip.shape[-2:], mode='bilinear', align_corners=False)\n",
        "            x = torch.cat([x, skip], dim=1); x = dec(x)\n",
        "        return self.final_conv(x)\n",
        "\n",
        "class DiagnosticUNet(nn.Module): # Stage 2 Model\n",
        "    def __init__(self, input_channels=1, output_channels=1, base_channels=32, depth=3):\n",
        "        super().__init__()\n",
        "        self.channels = [base_channels * min(2**i, 8) for i in range(depth)]\n",
        "        self.encoders, self.downsamplers = nn.ModuleList(), nn.ModuleList()\n",
        "        in_ch = input_channels\n",
        "        for i, out_ch in enumerate(self.channels):\n",
        "            self.encoders.append(self._conv_block(in_ch, out_ch))\n",
        "            if i < len(self.channels) - 1: self.downsamplers.append(nn.Conv2d(out_ch, out_ch, 3, stride=2, padding=1))\n",
        "            in_ch = out_ch\n",
        "        bottleneck_ch = self.channels[-1]\n",
        "        self.bottleneck = self._conv_block(self.channels[-1], bottleneck_ch)\n",
        "        self.upsamplers, self.decoders = nn.ModuleList(), nn.ModuleList()\n",
        "        for i in range(depth - 1, -1, -1):\n",
        "            in_ch = bottleneck_ch if i == depth - 1 else self.channels[i+1]\n",
        "            out_ch = self.channels[i]\n",
        "            self.upsamplers.append(nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2))\n",
        "            self.decoders.append(self._conv_block(out_ch * 2, out_ch))\n",
        "        self.final_conv = nn.Conv2d(self.channels[0], output_channels, 1) # No Tanh, outputs logits\n",
        "    def _conv_block(self, in_ch, out_ch): return nn.Sequential(nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True), nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True))\n",
        "    def forward(self, x):\n",
        "        skips = []\n",
        "        for i in range(len(self.encoders)):\n",
        "            x = self.encoders[i](x); skips.append(x)\n",
        "            if i < len(self.downsamplers): x = self.downsamplers[i](x)\n",
        "        x = self.bottleneck(x)\n",
        "        for i, (up, dec) in enumerate(zip(self.upsamplers, self.decoders)):\n",
        "            x = up(x); skip = skips[len(skips) - 1 - i]\n",
        "            if x.shape[-2:] != skip.shape[-2:]: x = F.interpolate(x, size=skip.shape[-2:], mode='bilinear', align_corners=False)\n",
        "            x = torch.cat([x, skip], dim=1); x = dec(x)\n",
        "        return self.final_conv(x)\n",
        "\n",
        "# --- 4. PRE-PROCESSING & CSI METRIC ---\n",
        "def generate_stage1_predictions(stage1_model, data_dir, output_dir, variable_indices, device):\n",
        "    print(\"--- Generating Stage 1 Predictions for Diagnostic Network Training ---\")\n",
        "    for split in ['train', 'val']:\n",
        "        print(f\"Processing '{split}' split...\")\n",
        "        split_dir = data_dir / split\n",
        "        output_split_dir = output_dir / split\n",
        "        output_split_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        predictor_files = sorted(list(split_dir.glob('*_predictor.npy')))\n",
        "        stats = joblib.load(data_dir / 'normalization_stats_multi_variable.joblib')\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for pred_file in tqdm(predictor_files, desc=f\"Generating Stage 1 preds for {split}\"):\n",
        "                full_predictor = np.load(pred_file).astype(np.float32)\n",
        "                predictor_subset = full_predictor[variable_indices, :, :]\n",
        "                mean_subset = stats['predictor_mean'][variable_indices, None, None]\n",
        "                std_subset = stats['predictor_std'][variable_indices, None, None]\n",
        "                predictor_norm = (predictor_subset - mean_subset) / (std_subset + 1e-8)\n",
        "\n",
        "                prediction_norm = stage1_model(torch.from_numpy(predictor_norm).unsqueeze(0).to(device)).cpu().numpy().squeeze()\n",
        "                prediction_denorm = prediction_norm * (stats['target_std'] + 1e-8) + stats['target_mean']\n",
        "\n",
        "                save_path = output_split_dir / f\"pred_{pred_file.stem.replace('_predictor','')}.npy\"\n",
        "                np.save(save_path, prediction_denorm)\n",
        "    print(\"--- Stage 1 Prediction Generation Complete ---\")\n",
        "\n",
        "def calculate_csi_from_mask(pred_mask, true_mask):\n",
        "    hits = (pred_mask & true_mask).sum().item()\n",
        "    misses = (~pred_mask & true_mask).sum().item()\n",
        "    false_alarms = (pred_mask & ~true_mask).sum().item()\n",
        "    return hits / (hits + misses + false_alarms) if (hits + misses + false_alarms) > 0 else 0.0\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1.0):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "    def forward(self, y_pred, y_true):\n",
        "        y_pred_sig = torch.sigmoid(y_pred)\n",
        "        y_pred_flat = y_pred_sig.contiguous().view(-1)\n",
        "        y_true_flat = y_true.contiguous().view(-1)\n",
        "        intersection = (y_pred_flat * y_true_flat).sum()\n",
        "        return 1 - (2. * intersection + self.smooth) / (y_pred_flat.sum() + y_true_flat.sum() + self.smooth)\n",
        "\n",
        "# --- 5. MAIN TRAINING SCRIPT ---\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"🎯 Training Stage 2 Diagnostic Network on device: {device}\")\n",
        "\n",
        "    stage1_model = FlexibleAblationModel(input_channels=INPUT_CHANNELS).to(device)\n",
        "    stage1_model.load_state_dict(torch.load(STAGE_1_MODEL_PATH, map_location=device))\n",
        "    stage1_model.eval()\n",
        "\n",
        "    stage1_preds_dir = OUTPUT_DIR / 'stage1_predictions_for_diagnostic'\n",
        "    generate_stage1_predictions(stage1_model, DATA_DIR, stage1_preds_dir, VARIABLE_INDICES, device)\n",
        "\n",
        "    train_dataset = DiagnosticDataset(DATA_DIR, 'train', stage1_preds_dir)\n",
        "    val_dataset = DiagnosticDataset(DATA_DIR, 'val', stage1_preds_dir)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    model = DiagnosticUNet().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "    bce_loss = nn.BCEWithLogitsLoss()\n",
        "    dice_loss = DiceLoss()\n",
        "\n",
        "    best_csi = 0.0\n",
        "    print(f\"\\nStarting Stage 2 Diagnostic training for {EPOCHS} epochs...\")\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Diagnostic Train]\")\n",
        "        for stage1_pred, true_mask in pbar:\n",
        "            stage1_pred, true_mask = stage1_pred.to(device), true_mask.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            pred_logits = model(stage1_pred)\n",
        "\n",
        "            loss_bce = bce_loss(pred_logits, true_mask)\n",
        "            loss_dice = dice_loss(pred_logits, true_mask)\n",
        "\n",
        "            loss = (loss_bce * LAMBDA_BCE) + (loss_dice * LAMBDA_DICE)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "        model.eval()\n",
        "        total_csi = 0.0\n",
        "        with torch.no_grad():\n",
        "            for stage1_pred_val, true_mask_val in val_loader:\n",
        "                stage1_pred_val, true_mask_val = stage1_pred_val.to(device), true_mask_val.to(device)\n",
        "                pred_logits_val = model(stage1_pred_val)\n",
        "                pred_mask_val = (torch.sigmoid(pred_logits_val) > 0.5)\n",
        "                total_csi += calculate_csi_from_mask(pred_mask_val, true_mask_val.bool())\n",
        "        avg_csi = total_csi / len(val_loader)\n",
        "        print(f\"Epoch {epoch+1}/{EPOCHS} | Validation CSI @ {DIAGNOSTIC_THRESHOLD_K}K: {avg_csi:.4f}\")\n",
        "\n",
        "        if avg_csi > best_csi:\n",
        "            best_csi = avg_csi\n",
        "            save_path = OUTPUT_DIR / 'best_diagnostic_model.pt'\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f\"✅ New best CSI! Model saved to {save_path}\")\n",
        "        gc.collect(); torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"\\n🎉 Diagnostic Network training complete! Best CSI achieved: {best_csi:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NA9fdXou_tZ",
        "outputId": "ba5d3050-1afa-4699-f09a-f02b0c999dc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Starting final evaluation on device: cuda\n",
            "Loaded 'test' dataset with 150 samples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Test Set: 100%|██████████| 150/150 [04:02<00:00,  1.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "================================================================================\n",
            "🏆 FINAL PIPELINE EVALUATION REPORT 🏆\n",
            "================================================================================\n",
            "                              0       1\n",
            "Stage1_rmse              9.0806     NaN\n",
            "Stage1_csi_230K          0.4293     NaN\n",
            "Stage1_csi_220K          0.1607     NaN\n",
            "Stage1_csi_210K          0.0587     NaN\n",
            "Final_Pipeline_rmse         NaN  9.0839\n",
            "Final_Pipeline_csi_230K     NaN  0.4293\n",
            "Final_Pipeline_csi_220K     NaN  0.1607\n",
            "Final_Pipeline_csi_210K     NaN  0.0587\n",
            "================================================================================\n",
            "\n",
            "💾 Detailed results saved to: /content/drive/My Drive/AR_Downscaling/final_evaluation_results/final_pipeline_evaluation.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Finding best cases: 100%|██████████| 150/150 [00:01<00:00, 142.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating 3 visualizations for the most intense cases...\n",
            "✅ Saved diagnostic figure to /content/drive/My Drive/AR_Downscaling/final_evaluation_results/final_pipeline_figure_20230807_1200.png\n",
            "✅ Saved diagnostic figure to /content/drive/My Drive/AR_Downscaling/final_evaluation_results/final_pipeline_figure_20230615_1800.png\n",
            "✅ Saved diagnostic figure to /content/drive/My Drive/AR_Downscaling/final_evaluation_results/final_pipeline_figure_20230807_1800.png\n",
            "\n",
            "🎉 Final evaluation and visualization complete!\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# This script performs the final, comprehensive evaluation and visualization\n",
        "# of the complete two-stage \"Forecast and Diagnose\" pipeline.\n",
        "# VERSION 2: Corrected ValueError during test set iteration.\n",
        "#\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import joblib\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from scipy.stats import wasserstein_distance\n",
        "from scipy.ndimage import sobel\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as colors\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "PROJECT_PATH = Path('/content/drive/My Drive/AR_Downscaling')\n",
        "DATA_DIR = PROJECT_PATH / 'final_dataset_multi_variable'\n",
        "ABLATION_MODEL_DIR = PROJECT_PATH / 'ablation_study_models'\n",
        "DIAGNOSTIC_MODEL_DIR = PROJECT_PATH / 'final_diagnostic_model'\n",
        "OUTPUT_DIR = PROJECT_PATH / 'final_evaluation_results'\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# --- Models to Evaluate ---\n",
        "STAGE_1_MODEL_PATH = ABLATION_MODEL_DIR / 'ablation_remove_IVT.pt'\n",
        "STAGE_2_MODEL_PATH = DIAGNOSTIC_MODEL_DIR / 'best_diagnostic_model.pt'\n",
        "\n",
        "# --- Evaluation Configuration ---\n",
        "CSI_THRESHOLDS_K = [230.0, 220.0, 210.0]\n",
        "DIAGNOSTIC_THRESHOLD_K = 220.0\n",
        "NUM_CASES_TO_PLOT = 3\n",
        "COLORMAP = 'CMRmap_r'\n",
        "\n",
        "# --- Model & Data Configuration ---\n",
        "ALL_VARIABLES = ['IVT', 'T500', 'T850', 'RH700', 'W500']\n",
        "VARIABLES_TO_USE = ['T500', 'T850', 'RH700', 'W500']\n",
        "VARIABLE_INDICES = [ALL_VARIABLES.index(v) for v in VARIABLES_TO_USE]\n",
        "INPUT_CHANNELS = len(VARIABLE_INDICES)\n",
        "\n",
        "# --- 2. DATASET & MODEL ARCHITECTURES ---\n",
        "class MultiVariableARDataset(Dataset):\n",
        "    def __init__(self, data_dir: Path, split: str = 'test'):\n",
        "        self.split_dir = data_dir / split\n",
        "        self.predictor_files = sorted(list(self.split_dir.glob('*_predictor.npy')))\n",
        "        self.stats = joblib.load(data_dir / 'normalization_stats_multi_variable.joblib')\n",
        "        if not self.predictor_files: raise FileNotFoundError(f\"No predictor files in {self.split_dir}\")\n",
        "        print(f\"Loaded '{split}' dataset with {len(self.predictor_files)} samples.\")\n",
        "\n",
        "    def __len__(self): return len(self.predictor_files)\n",
        "    def __getitem__(self, idx):\n",
        "        pred_path = self.predictor_files[idx]\n",
        "        targ_path = Path(str(pred_path).replace('_predictor.npy', '_target.npy'))\n",
        "        predictor_data = np.load(pred_path).astype(np.float32)\n",
        "        target_data = np.load(targ_path).astype(np.float32)\n",
        "        predictor_norm = (predictor_data - self.stats['predictor_mean'][:, None, None]) / (self.stats['predictor_std'][:, None, None] + 1e-8)\n",
        "        target_norm = (target_data - self.stats['target_mean']) / (self.stats['target_std'] + 1e-8)\n",
        "        return torch.from_numpy(predictor_norm), torch.from_numpy(target_norm).unsqueeze(0), pred_path.stem.replace('_predictor','')\n",
        "\n",
        "class SimplifiedAttention(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.channel_att = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Conv2d(channels, channels // 16, 1), nn.ReLU(inplace=True), nn.Conv2d(channels // 16, channels, 1), nn.Sigmoid())\n",
        "        self.spatial_att = nn.Sequential(nn.Conv2d(channels, 1, 7, padding=3), nn.Sigmoid())\n",
        "    def forward(self, x):\n",
        "        ch_att = self.channel_att(x); x = x * ch_att; sp_att = self.spatial_att(x); x = x * sp_att\n",
        "        return x\n",
        "\n",
        "class FlexibleAblationModel(nn.Module): # Stage 1 Model\n",
        "    def __init__(self, input_channels, base_channels=64, depth=4, use_attention=True):\n",
        "        super().__init__()\n",
        "        self.use_attention, self.depth = use_attention, depth\n",
        "        self.channels = [base_channels * min(2**i, 8) for i in range(depth)]\n",
        "        self.encoders, self.downsamplers = nn.ModuleList(), nn.ModuleList()\n",
        "        in_ch = input_channels\n",
        "        for i, out_ch in enumerate(self.channels):\n",
        "            self.encoders.append(self._conv_block(in_ch, out_ch))\n",
        "            if i < len(self.channels) - 1: self.downsamplers.append(nn.Conv2d(out_ch, out_ch, 3, stride=2, padding=1))\n",
        "            in_ch = out_ch\n",
        "        bottleneck_ch = self.channels[-1]\n",
        "        self.bottleneck = self._conv_block(self.channels[-1], bottleneck_ch)\n",
        "        if self.use_attention: self.attention = SimplifiedAttention(bottleneck_ch)\n",
        "        self.upsamplers, self.decoders = nn.ModuleList(), nn.ModuleList()\n",
        "        for i in range(depth - 1, -1, -1):\n",
        "            in_ch = bottleneck_ch if i == depth - 1 else self.channels[i+1]\n",
        "            out_ch = self.channels[i]\n",
        "            self.upsamplers.append(nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2))\n",
        "            self.decoders.append(self._conv_block(out_ch * 2, out_ch))\n",
        "        self.final_conv = nn.Sequential(nn.Conv2d(self.channels[0], self.channels[0] // 2, 3, padding=1), nn.BatchNorm2d(self.channels[0] // 2), nn.ReLU(inplace=True), nn.Conv2d(self.channels[0] // 2, 1, 1))\n",
        "    def _conv_block(self, in_ch, out_ch): return nn.Sequential(nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True), nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True))\n",
        "    def forward(self, x):\n",
        "        skips = []\n",
        "        for i in range(len(self.encoders)):\n",
        "            x = self.encoders[i](x); skips.append(x)\n",
        "            if i < len(self.downsamplers): x = self.downsamplers[i](x)\n",
        "        x = self.bottleneck(x)\n",
        "        if self.use_attention: x = self.attention(x)\n",
        "        for i, (up, dec) in enumerate(zip(self.upsamplers, self.decoders)):\n",
        "            x = up(x); skip = skips[len(skips) - 1 - i]\n",
        "            if x.shape[-2:] != skip.shape[-2:]: x = F.interpolate(x, size=skip.shape[-2:], mode='bilinear', align_corners=False)\n",
        "            x = torch.cat([x, skip], dim=1); x = dec(x)\n",
        "        return self.final_conv(x)\n",
        "\n",
        "class DiagnosticUNet(nn.Module): # Stage 2 Model\n",
        "    def __init__(self, input_channels=1, output_channels=1, base_channels=32, depth=3):\n",
        "        super().__init__()\n",
        "        self.channels = [base_channels * min(2**i, 8) for i in range(depth)]\n",
        "        self.encoders, self.downsamplers = nn.ModuleList(), nn.ModuleList()\n",
        "        in_ch = input_channels\n",
        "        for i, out_ch in enumerate(self.channels):\n",
        "            self.encoders.append(self._conv_block(in_ch, out_ch))\n",
        "            if i < len(self.channels) - 1: self.downsamplers.append(nn.Conv2d(out_ch, out_ch, 3, stride=2, padding=1))\n",
        "            in_ch = out_ch\n",
        "        bottleneck_ch = self.channels[-1]\n",
        "        self.bottleneck = self._conv_block(self.channels[-1], bottleneck_ch)\n",
        "        self.upsamplers, self.decoders = nn.ModuleList(), nn.ModuleList()\n",
        "        for i in range(depth - 1, -1, -1):\n",
        "            in_ch = bottleneck_ch if i == depth - 1 else self.channels[i+1]\n",
        "            out_ch = self.channels[i]\n",
        "            self.upsamplers.append(nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2))\n",
        "            self.decoders.append(self._conv_block(out_ch * 2, out_ch))\n",
        "        self.final_conv = nn.Conv2d(self.channels[0], output_channels, 1)\n",
        "    def _conv_block(self, in_ch, out_ch): return nn.Sequential(nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True), nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True))\n",
        "    def forward(self, x):\n",
        "        skips = []\n",
        "        for i in range(len(self.encoders)):\n",
        "            x = self.encoders[i](x); skips.append(x)\n",
        "            if i < len(self.downsamplers): x = self.downsamplers[i](x)\n",
        "        x = self.bottleneck(x)\n",
        "        for i, (up, dec) in enumerate(zip(self.upsamplers, self.decoders)):\n",
        "            x = up(x); skip = skips[len(skips) - 1 - i]\n",
        "            if x.shape[-2:] != skip.shape[-2:]: x = F.interpolate(x, size=skip.shape[-2:], mode='bilinear', align_corners=False)\n",
        "            x = torch.cat([x, skip], dim=1); x = dec(x)\n",
        "        return self.final_conv(x)\n",
        "\n",
        "# --- 3. METRIC & HELPER FUNCTIONS ---\n",
        "def calculate_detailed_csi(pred_k, true_k, threshold_k):\n",
        "    pred_mask = pred_k <= threshold_k; true_mask = true_k <= threshold_k\n",
        "    hits = (pred_mask & true_mask).sum()\n",
        "    misses = (~pred_mask & true_mask).sum()\n",
        "    false_alarms = (pred_mask & ~true_mask).sum()\n",
        "    csi = hits / (hits + misses + false_alarms) if (hits + misses + false_alarms) > 0 else 0.0\n",
        "    return csi\n",
        "\n",
        "def calculate_all_metrics(pred_norm, true_norm, stats):\n",
        "    pred_k = pred_norm * (stats['target_std'] + 1e-8) + stats['target_mean']\n",
        "    true_k = true_norm * (stats['target_std'] + 1e-8) + stats['target_mean']\n",
        "    metrics = {'rmse': np.sqrt(np.mean((pred_k - true_k)**2))}\n",
        "    for thr in CSI_THRESHOLDS_K:\n",
        "        metrics[f'csi_{int(thr)}K'] = calculate_detailed_csi(pred_k, true_k, thr)\n",
        "    return metrics\n",
        "\n",
        "def find_best_test_cases(dataset, threshold_k, num_cases):\n",
        "    scores = []\n",
        "    for i in tqdm(range(len(dataset)), desc=\"Finding best cases\"):\n",
        "        _, target_norm, _ = dataset[i]\n",
        "        target_k = target_norm.numpy().squeeze() * (dataset.stats['target_std'] + 1e-8) + dataset.stats['target_mean']\n",
        "        score = (target_k <= threshold_k).sum()\n",
        "        scores.append((score, i))\n",
        "    scores.sort(key=lambda x: x[0], reverse=True)\n",
        "    return [idx for _, idx in scores[:num_cases]]\n",
        "\n",
        "# --- 4. VISUALIZATION FUNCTION ---\n",
        "def create_diagnostic_figure(case_data, stage1_model, stage2_model, stats, device):\n",
        "    predictor, target_norm, case_name = case_data\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictor_subset = predictor[VARIABLE_INDICES, :, :].unsqueeze(0).to(device)\n",
        "        stage1_pred_norm = stage1_model(predictor_subset)\n",
        "        stage2_pred_logits = stage2_model(stage1_pred_norm)\n",
        "        stage2_pred_prob = torch.sigmoid(stage2_pred_logits)\n",
        "\n",
        "    stage1_pred_k = stage1_pred_norm.cpu().numpy().squeeze() * (stats['target_std'] + 1e-8) + stats['target_mean']\n",
        "    ground_truth_k = target_norm.numpy().squeeze() * (stats['target_std'] + 1e-8) + stats['target_mean']\n",
        "    threat_mask = stage2_pred_prob.cpu().numpy().squeeze()\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(21, 7), facecolor='white')\n",
        "    fig.suptitle(f'Final Pipeline Evaluation for Case: {case_name}', fontsize=20, fontweight='bold')\n",
        "\n",
        "    norm = colors.PowerNorm(gamma=0.4, vmin=200, vmax=275)\n",
        "\n",
        "    axes[0].imshow(ground_truth_k, cmap=COLORMAP, norm=norm)\n",
        "    axes[0].set_title('A) Ground Truth TBB', fontsize=16)\n",
        "\n",
        "    axes[1].imshow(stage1_pred_k, cmap=COLORMAP, norm=norm)\n",
        "    axes[1].set_title('B) Stage 1: Quantitative Forecast', fontsize=16)\n",
        "\n",
        "    axes[2].imshow(ground_truth_k, cmap='gray', norm=norm)\n",
        "    axes[2].imshow(threat_mask, cmap='Reds', alpha=(threat_mask * 0.8), vmin=0, vmax=1)\n",
        "    axes[2].set_title('C) Final Product: Threat Highlight', fontsize=16)\n",
        "\n",
        "    for ax in axes:\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "\n",
        "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    save_path = OUTPUT_DIR / f\"final_pipeline_figure_{case_name}.png\"\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"✅ Saved diagnostic figure to {save_path}\")\n",
        "\n",
        "# --- 5. MAIN SCRIPT ---\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"🔧 Starting final evaluation on device: {device}\")\n",
        "\n",
        "    test_dataset = MultiVariableARDataset(DATA_DIR, 'test')\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "    stats = test_dataset.stats\n",
        "\n",
        "    stage1_model = FlexibleAblationModel(input_channels=INPUT_CHANNELS).to(device)\n",
        "    stage1_model.load_state_dict(torch.load(STAGE_1_MODEL_PATH, map_location=device))\n",
        "    stage1_model.eval()\n",
        "\n",
        "    stage2_model = DiagnosticUNet().to(device)\n",
        "    stage2_model.load_state_dict(torch.load(STAGE_2_MODEL_PATH, map_location=device))\n",
        "    stage2_model.eval()\n",
        "\n",
        "    # --- Comprehensive Evaluation ---\n",
        "    stage1_metrics_list, final_pipeline_metrics_list = [], []\n",
        "    with torch.no_grad():\n",
        "        # --- KEY FIX: Unpack all three items from the dataloader ---\n",
        "        for predictor, target, _ in tqdm(test_loader, desc=\"Evaluating Test Set\"):\n",
        "            predictor_subset = predictor[:, VARIABLE_INDICES, :, :].to(device)\n",
        "\n",
        "            # Stage 1 Prediction\n",
        "            stage1_pred_norm = stage1_model(predictor_subset)\n",
        "            stage1_metrics = calculate_all_metrics(stage1_pred_norm.cpu().numpy().squeeze(), target.numpy().squeeze(), stats)\n",
        "            stage1_metrics_list.append(stage1_metrics)\n",
        "\n",
        "            # Stage 2 Prediction\n",
        "            stage2_pred_logits = stage2_model(stage1_pred_norm)\n",
        "            stage2_pred_mask = (torch.sigmoid(stage2_pred_logits) > 0.5).cpu().numpy().squeeze()\n",
        "\n",
        "            final_pred_k = np.where(stage2_pred_mask, stage1_pred_norm.cpu().numpy().squeeze() * (stats['target_std'] + 1e-8) + stats['target_mean'], 300)\n",
        "            true_k = target.numpy().squeeze() * (stats['target_std'] + 1e-8) + stats['target_mean']\n",
        "\n",
        "            pipeline_metrics = {'rmse': np.sqrt(np.mean((final_pred_k - true_k)**2))}\n",
        "            for thr in CSI_THRESHOLDS_K:\n",
        "                pipeline_metrics[f'csi_{int(thr)}K'] = calculate_detailed_csi(final_pred_k, true_k, thr)\n",
        "            final_pipeline_metrics_list.append(pipeline_metrics)\n",
        "\n",
        "    # --- Reporting ---\n",
        "    stage1_df = pd.DataFrame(stage1_metrics_list).mean().add_prefix('Stage1_')\n",
        "    final_df = pd.DataFrame(final_pipeline_metrics_list).mean().add_prefix('Final_Pipeline_')\n",
        "\n",
        "    report_df = pd.concat([stage1_df, final_df], axis=1)\n",
        "\n",
        "    print(\"\\n\\n\" + \"=\"*80)\n",
        "    print(\"🏆 FINAL PIPELINE EVALUATION REPORT 🏆\")\n",
        "    print(\"=\"*80)\n",
        "    print(report_df.round(4))\n",
        "    print(\"=\"*80)\n",
        "    report_df.to_csv(OUTPUT_DIR / 'final_pipeline_evaluation.csv')\n",
        "    print(f\"\\n💾 Detailed results saved to: {OUTPUT_DIR / 'final_pipeline_evaluation.csv'}\")\n",
        "\n",
        "    # --- Visualization ---\n",
        "    best_case_indices = find_best_test_cases(test_dataset, DIAGNOSTIC_THRESHOLD_K, NUM_CASES_TO_PLOT)\n",
        "    print(f\"\\nGenerating {len(best_case_indices)} visualizations for the most intense cases...\")\n",
        "    for idx in best_case_indices:\n",
        "        case_data = test_dataset[idx]\n",
        "        create_diagnostic_figure(case_data, stage1_model, stage2_model, stats, device)\n",
        "\n",
        "    print(\"\\n🎉 Final evaluation and visualization complete!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# This script performs the final, comprehensive evaluation and visualization\n",
        "# of the complete two-stage \"Forecast and Diagnose\" pipeline.\n",
        "# VERSION 3: Corrected TypeError in visualization function.\n",
        "#\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import joblib\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from scipy.ndimage import sobel\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as colors\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "PROJECT_PATH = Path('/content/drive/My Drive/AR_Downscaling')\n",
        "DATA_DIR = PROJECT_PATH / 'final_dataset_multi_variable'\n",
        "ABLATION_MODEL_DIR = PROJECT_PATH / 'ablation_study_models'\n",
        "DIAGNOSTIC_MODEL_DIR = PROJECT_PATH / 'final_diagnostic_model'\n",
        "OUTPUT_DIR = PROJECT_PATH / 'final_publication_figures'\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# --- Models to Evaluate ---\n",
        "STAGE_1_MODEL_PATH = ABLATION_MODEL_DIR / 'ablation_remove_IVT.pt'\n",
        "STAGE_2_MODEL_PATH = DIAGNOSTIC_MODEL_DIR / 'best_diagnostic_model.pt'\n",
        "\n",
        "# --- Evaluation Configuration ---\n",
        "DIAGNOSTIC_THRESHOLD_K = 220.0\n",
        "NUM_CASES_TO_PLOT = 3\n",
        "COLORMAP = 'CMRmap_r'\n",
        "\n",
        "# --- Model & Data Configuration ---\n",
        "ALL_VARIABLES = ['IVT', 'T500', 'T850', 'RH700', 'W500']\n",
        "VARIABLES_TO_USE = ['T500', 'T850', 'RH700', 'W500']\n",
        "VARIABLE_INDICES = [ALL_VARIABLES.index(v) for v in VARIABLES_TO_USE]\n",
        "INPUT_CHANNELS = len(VARIABLE_INDICES)\n",
        "\n",
        "# --- 2. DATASET & MODEL ARCHITECTURES ---\n",
        "class MultiVariableARDataset(Dataset):\n",
        "    def __init__(self, data_dir: Path, split: str = 'test'):\n",
        "        self.split_dir = data_dir / split\n",
        "        self.predictor_files = sorted(list(self.split_dir.glob('*_predictor.npy')))\n",
        "        self.stats = joblib.load(data_dir / 'normalization_stats_multi_variable.joblib')\n",
        "        if not self.predictor_files: raise FileNotFoundError(f\"No predictor files in {self.split_dir}\")\n",
        "        print(f\"Loaded '{split}' dataset with {len(self.predictor_files)} samples.\")\n",
        "\n",
        "    def __len__(self): return len(self.predictor_files)\n",
        "    def __getitem__(self, idx):\n",
        "        pred_path = self.predictor_files[idx]\n",
        "        targ_path = Path(str(pred_path).replace('_predictor.npy', '_target.npy'))\n",
        "        predictor_data = np.load(pred_path).astype(np.float32)\n",
        "        target_data = np.load(targ_path).astype(np.float32)\n",
        "        predictor_norm = (predictor_data - self.stats['predictor_mean'][:, None, None]) / (self.stats['predictor_std'][:, None, None] + 1e-8)\n",
        "        # Return the unnormalized target (as a tensor) for creating the ground truth mask later\n",
        "        return torch.from_numpy(predictor_norm), torch.from_numpy(target_data), pred_path.stem.replace('_predictor','')\n",
        "\n",
        "class SimplifiedAttention(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.channel_att = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Conv2d(channels, channels // 16, 1), nn.ReLU(inplace=True), nn.Conv2d(channels // 16, channels, 1), nn.Sigmoid())\n",
        "        self.spatial_att = nn.Sequential(nn.Conv2d(channels, 1, 7, padding=3), nn.Sigmoid())\n",
        "    def forward(self, x):\n",
        "        ch_att = self.channel_att(x); x = x * ch_att; sp_att = self.spatial_att(x); x = x * sp_att\n",
        "        return x\n",
        "\n",
        "class FlexibleAblationModel(nn.Module): # Stage 1 Model\n",
        "    def __init__(self, input_channels, base_channels=64, depth=4, use_attention=True):\n",
        "        super().__init__()\n",
        "        self.use_attention, self.depth = use_attention, depth\n",
        "        self.channels = [base_channels * min(2**i, 8) for i in range(depth)]\n",
        "        self.encoders, self.downsamplers = nn.ModuleList(), nn.ModuleList()\n",
        "        in_ch = input_channels\n",
        "        for i, out_ch in enumerate(self.channels):\n",
        "            self.encoders.append(self._conv_block(in_ch, out_ch))\n",
        "            if i < len(self.channels) - 1: self.downsamplers.append(nn.Conv2d(out_ch, out_ch, 3, stride=2, padding=1))\n",
        "            in_ch = out_ch\n",
        "        bottleneck_ch = self.channels[-1]\n",
        "        self.bottleneck = self._conv_block(self.channels[-1], bottleneck_ch)\n",
        "        if self.use_attention: self.attention = SimplifiedAttention(bottleneck_ch)\n",
        "        self.upsamplers, self.decoders = nn.ModuleList(), nn.ModuleList()\n",
        "        for i in range(depth - 1, -1, -1):\n",
        "            in_ch = bottleneck_ch if i == depth - 1 else self.channels[i+1]\n",
        "            out_ch = self.channels[i]\n",
        "            self.upsamplers.append(nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2))\n",
        "            self.decoders.append(self._conv_block(out_ch * 2, out_ch))\n",
        "        self.final_conv = nn.Sequential(nn.Conv2d(self.channels[0], self.channels[0] // 2, 3, padding=1), nn.BatchNorm2d(self.channels[0] // 2), nn.ReLU(inplace=True), nn.Conv2d(self.channels[0] // 2, 1, 1))\n",
        "    def _conv_block(self, in_ch, out_ch): return nn.Sequential(nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True), nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True))\n",
        "    def forward(self, x):\n",
        "        skips = []\n",
        "        for i in range(len(self.encoders)):\n",
        "            x = self.encoders[i](x); skips.append(x)\n",
        "            if i < len(self.downsamplers): x = self.downsamplers[i](x)\n",
        "        x = self.bottleneck(x)\n",
        "        if self.use_attention: x = self.attention(x)\n",
        "        for i, (up, dec) in enumerate(zip(self.upsamplers, self.decoders)):\n",
        "            x = up(x); skip = skips[len(skips) - 1 - i]\n",
        "            if x.shape[-2:] != skip.shape[-2:]: x = F.interpolate(x, size=skip.shape[-2:], mode='bilinear', align_corners=False)\n",
        "            x = torch.cat([x, skip], dim=1); x = dec(x)\n",
        "        return self.final_conv(x)\n",
        "\n",
        "class DiagnosticUNet(nn.Module): # Stage 2 Model\n",
        "    def __init__(self, input_channels=1, output_channels=1, base_channels=32, depth=3):\n",
        "        super().__init__()\n",
        "        self.channels = [base_channels * min(2**i, 8) for i in range(depth)]\n",
        "        self.encoders, self.downsamplers = nn.ModuleList(), nn.ModuleList()\n",
        "        in_ch = input_channels\n",
        "        for i, out_ch in enumerate(self.channels):\n",
        "            self.encoders.append(self._conv_block(in_ch, out_ch))\n",
        "            if i < len(self.channels) - 1: self.downsamplers.append(nn.Conv2d(out_ch, out_ch, 3, stride=2, padding=1))\n",
        "            in_ch = out_ch\n",
        "        bottleneck_ch = self.channels[-1]\n",
        "        self.bottleneck = self._conv_block(self.channels[-1], bottleneck_ch)\n",
        "        self.upsamplers, self.decoders = nn.ModuleList(), nn.ModuleList()\n",
        "        for i in range(depth - 1, -1, -1):\n",
        "            in_ch = bottleneck_ch if i == depth - 1 else self.channels[i+1]\n",
        "            out_ch = self.channels[i]\n",
        "            self.upsamplers.append(nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2))\n",
        "            self.decoders.append(self._conv_block(out_ch * 2, out_ch))\n",
        "        self.final_conv = nn.Conv2d(self.channels[0], output_channels, 1)\n",
        "    def _conv_block(self, in_ch, out_ch): return nn.Sequential(nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True), nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True))\n",
        "    def forward(self, x):\n",
        "        skips = []\n",
        "        for i in range(len(self.encoders)):\n",
        "            x = self.encoders[i](x); skips.append(x)\n",
        "            if i < len(self.downsamplers): x = self.downsamplers[i](x)\n",
        "        x = self.bottleneck(x)\n",
        "        for i, (up, dec) in enumerate(zip(self.upsamplers, self.decoders)):\n",
        "            x = up(x); skip = skips[len(skips) - 1 - i]\n",
        "            if x.shape[-2:] != skip.shape[-2:]: x = F.interpolate(x, size=skip.shape[-2:], mode='bilinear', align_corners=False)\n",
        "            x = torch.cat([x, skip], dim=1); x = dec(x)\n",
        "        return self.final_conv(x)\n",
        "\n",
        "# --- 3. HELPER FUNCTIONS ---\n",
        "def find_best_test_cases(dataset, threshold_k, num_cases):\n",
        "    scores = []\n",
        "    for i in tqdm(range(len(dataset)), desc=\"Finding best cases\"):\n",
        "        _, target_k_tensor, _ = dataset[i]\n",
        "        score = (target_k_tensor.numpy() <= threshold_k).sum()\n",
        "        scores.append((score, i))\n",
        "    scores.sort(key=lambda x: x[0], reverse=True)\n",
        "    return [idx for _, idx in scores[:num_cases]]\n",
        "\n",
        "def calculate_csi_from_mask(pred_mask, true_mask):\n",
        "    # This function now expects NumPy arrays\n",
        "    hits = (pred_mask & true_mask).sum()\n",
        "    misses = (~pred_mask & true_mask).sum()\n",
        "    false_alarms = (pred_mask & ~true_mask).sum()\n",
        "    return hits / (hits + misses + false_alarms) if (hits + misses + false_alarms) > 0 else 0.0\n",
        "\n",
        "# --- 4. VISUALIZATION FUNCTION ---\n",
        "def create_diagnostic_figure(case_data, stage1_model, stage2_model, stats, device):\n",
        "    predictor_norm, ground_truth_k_tensor, case_name = case_data\n",
        "    ground_truth_k = ground_truth_k_tensor.numpy() # Convert to numpy for plotting/masking\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictor_subset = predictor_norm[VARIABLE_INDICES, :, :].unsqueeze(0).to(device)\n",
        "        stage1_pred_norm = stage1_model(predictor_subset)\n",
        "        stage2_pred_logits = stage2_model(stage1_pred_norm)\n",
        "        stage2_pred_prob = torch.sigmoid(stage2_pred_logits)\n",
        "\n",
        "    stage1_pred_k = stage1_pred_norm.cpu().numpy().squeeze() * (stats['target_std'] + 1e-8) + stats['target_mean']\n",
        "    threat_mask = stage2_pred_prob.cpu().numpy().squeeze()\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(21, 7), facecolor='white')\n",
        "    fig.suptitle(f'Final Pipeline Evaluation for Case: {case_name}', fontsize=20, fontweight='bold')\n",
        "\n",
        "    norm = colors.PowerNorm(gamma=0.4, vmin=200, vmax=275)\n",
        "\n",
        "    # Panel A: Ground Truth\n",
        "    axes[0].imshow(ground_truth_k, cmap=COLORMAP, norm=norm)\n",
        "    true_mask = (ground_truth_k <= DIAGNOSTIC_THRESHOLD_K)\n",
        "    axes[0].set_title('A) Ground Truth TBB', fontsize=16)\n",
        "\n",
        "    # Panel B: Stage 1 Forecast\n",
        "    axes[1].imshow(stage1_pred_k, cmap=COLORMAP, norm=norm)\n",
        "    stage1_mask = (stage1_pred_k <= DIAGNOSTIC_THRESHOLD_K)\n",
        "    # --- KEY FIX: Ensure both masks are numpy arrays before passing to CSI function ---\n",
        "    stage1_csi = calculate_csi_from_mask(stage1_mask, true_mask)\n",
        "    axes[1].set_title(f'B) Stage 1 Forecast (CSI: {stage1_csi:.3f})', fontsize=16)\n",
        "\n",
        "    # Panel C: Final \"Threat Highlight\" Product\n",
        "    axes[2].imshow(ground_truth_k, cmap='gray', norm=norm)\n",
        "    axes[2].imshow(threat_mask, cmap='Reds', alpha=(threat_mask * 0.7), vmin=0.2, vmax=1)\n",
        "    final_mask = (threat_mask > 0.5)\n",
        "    final_csi = calculate_csi_from_mask(final_mask, true_mask)\n",
        "    axes[2].set_title(f'C) Final Product: Threat Highlight (CSI: {final_csi:.3f})', fontsize=16)\n",
        "\n",
        "    for ax in axes:\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "\n",
        "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    save_path = OUTPUT_DIR / f\"final_pipeline_figure_{case_name}.png\"\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"✅ Saved diagnostic figure to {save_path}\")\n",
        "\n",
        "# --- 5. MAIN SCRIPT ---\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # --- Load Models ---\n",
        "    stage1_model = FlexibleAblationModel(input_channels=INPUT_CHANNELS).to(device)\n",
        "    stage1_model.load_state_dict(torch.load(STAGE_1_MODEL_PATH, map_location=device))\n",
        "    stage1_model.eval()\n",
        "    print(f\"✅ Loaded Stage 1 Model: {STAGE_1_MODEL_PATH.name}\")\n",
        "\n",
        "    stage2_model = DiagnosticUNet().to(device)\n",
        "    stage2_model.load_state_dict(torch.load(STAGE_2_MODEL_PATH, map_location=device))\n",
        "    stage2_model.eval()\n",
        "    print(f\"✅ Loaded Stage 2 Model: {STAGE_2_MODEL_PATH.name}\")\n",
        "\n",
        "    # --- Find and Visualize Best Cases ---\n",
        "    test_dataset = MultiVariableARDataset(DATA_DIR, 'test')\n",
        "    best_case_indices = find_best_test_cases(test_dataset, DIAGNOSTIC_THRESHOLD_K, NUM_CASES_TO_PLOT)\n",
        "\n",
        "    print(f\"\\nGenerating {len(best_case_indices)} visualizations for the most intense cases...\")\n",
        "    for idx in best_case_indices:\n",
        "        case_data = test_dataset[idx]\n",
        "        create_diagnostic_figure(case_data, stage1_model, stage2_model, test_dataset.stats, device)\n",
        "\n",
        "    print(\"\\n🎉 Final visualization complete!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RmW0s2-9fXg",
        "outputId": "28a10db0-a2c5-4afe-988c-9fd6d12c93bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded Stage 1 Model: ablation_remove_IVT.pt\n",
            "✅ Loaded Stage 2 Model: best_diagnostic_model.pt\n",
            "Loaded 'test' dataset with 150 samples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Finding best cases: 100%|██████████| 150/150 [00:01<00:00, 105.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating 3 visualizations for the most intense cases...\n",
            "✅ Saved diagnostic figure to /content/drive/My Drive/AR_Downscaling/final_publication_figures/final_pipeline_figure_20230807_1200.png\n",
            "✅ Saved diagnostic figure to /content/drive/My Drive/AR_Downscaling/final_publication_figures/final_pipeline_figure_20230615_1800.png\n",
            "✅ Saved diagnostic figure to /content/drive/My Drive/AR_Downscaling/final_publication_figures/final_pipeline_figure_20230807_1800.png\n",
            "\n",
            "🎉 Final visualization complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# This script generates the final, publication-quality figures that demonstrate\n",
        "# the operational output of the \"Forecast and Diagnose\" pipeline.\n",
        "# VERSION 3: Simplified to a clean, two-panel operational figure.\n",
        "#\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import joblib\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as colors\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "PROJECT_PATH = Path('/content/drive/My Drive/AR_Downscaling')\n",
        "DATA_DIR = PROJECT_PATH / 'final_dataset_multi_variable'\n",
        "ABLATION_MODEL_DIR = PROJECT_PATH / 'ablation_study_models'\n",
        "DIAGNOSTIC_MODEL_DIR = PROJECT_PATH / 'final_diagnostic_model'\n",
        "OUTPUT_DIR = PROJECT_PATH / 'final_publication_figures'\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# --- Models to Visualize ---\n",
        "STAGE_1_MODEL_PATH = ABLATION_MODEL_DIR / 'ablation_remove_IVT.pt'\n",
        "STAGE_2_MODEL_PATH = DIAGNOSTIC_MODEL_DIR / 'best_diagnostic_model.pt'\n",
        "\n",
        "# --- Visualization Configuration ---\n",
        "NUM_CASES_TO_PLOT = 3\n",
        "DIAGNOSTIC_THRESHOLD_K = 220.0\n",
        "COLORMAP = 'CMRmap_r'\n",
        "\n",
        "# --- Model & Data Configuration ---\n",
        "ALL_VARIABLES = ['IVT', 'T500', 'T850', 'RH700', 'W500']\n",
        "VARIABLES_TO_USE = ['T500', 'T850', 'RH700', 'W500']\n",
        "VARIABLE_INDICES = [ALL_VARIABLES.index(v) for v in VARIABLES_TO_USE]\n",
        "INPUT_CHANNELS = len(VARIABLE_INDICES)\n",
        "\n",
        "# --- 2. DATASET & MODEL ARCHITECTURES ---\n",
        "class MultiVariableARDataset(Dataset):\n",
        "    def __init__(self, data_dir: Path, split: str = 'test'):\n",
        "        self.split_dir = data_dir / split\n",
        "        self.predictor_files = sorted(list(self.split_dir.glob('*_predictor.npy')))\n",
        "        self.stats = joblib.load(data_dir / 'normalization_stats_multi_variable.joblib')\n",
        "        if not self.predictor_files: raise FileNotFoundError(f\"No predictor files in {self.split_dir}\")\n",
        "        print(f\"Loaded '{split}' dataset with {len(self.predictor_files)} samples.\")\n",
        "\n",
        "    def __len__(self): return len(self.predictor_files)\n",
        "    def __getitem__(self, idx):\n",
        "        pred_path = self.predictor_files[idx]\n",
        "        targ_path = Path(str(pred_path).replace('_predictor.npy', '_target.npy'))\n",
        "        predictor_data = np.load(pred_path).astype(np.float32)\n",
        "        target_data = np.load(targ_path).astype(np.float32)\n",
        "        predictor_norm = (predictor_data - self.stats['predictor_mean'][:, None, None]) / (self.stats['predictor_std'][:, None, None] + 1e-8)\n",
        "        return torch.from_numpy(predictor_norm), torch.from_numpy(target_data), pred_path.stem.replace('_predictor','')\n",
        "\n",
        "class SimplifiedAttention(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.channel_att = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Conv2d(channels, channels // 16, 1), nn.ReLU(inplace=True), nn.Conv2d(channels // 16, channels, 1), nn.Sigmoid())\n",
        "        self.spatial_att = nn.Sequential(nn.Conv2d(channels, 1, 7, padding=3), nn.Sigmoid())\n",
        "    def forward(self, x):\n",
        "        ch_att = self.channel_att(x); x = x * ch_att; sp_att = self.spatial_att(x); x = x * sp_att\n",
        "        return x\n",
        "\n",
        "class FlexibleAblationModel(nn.Module): # Stage 1 Model\n",
        "    def __init__(self, input_channels, base_channels=64, depth=4, use_attention=True):\n",
        "        super().__init__()\n",
        "        self.use_attention, self.depth = use_attention, depth\n",
        "        self.channels = [base_channels * min(2**i, 8) for i in range(depth)]\n",
        "        self.encoders, self.downsamplers = nn.ModuleList(), nn.ModuleList()\n",
        "        in_ch = input_channels\n",
        "        for i, out_ch in enumerate(self.channels):\n",
        "            self.encoders.append(self._conv_block(in_ch, out_ch))\n",
        "            if i < len(self.channels) - 1: self.downsamplers.append(nn.Conv2d(out_ch, out_ch, 3, stride=2, padding=1))\n",
        "            in_ch = out_ch\n",
        "        bottleneck_ch = self.channels[-1]\n",
        "        self.bottleneck = self._conv_block(self.channels[-1], bottleneck_ch)\n",
        "        if self.use_attention: self.attention = SimplifiedAttention(bottleneck_ch)\n",
        "        self.upsamplers, self.decoders = nn.ModuleList(), nn.ModuleList()\n",
        "        for i in range(depth - 1, -1, -1):\n",
        "            in_ch = bottleneck_ch if i == depth - 1 else self.channels[i+1]\n",
        "            out_ch = self.channels[i]\n",
        "            self.upsamplers.append(nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2))\n",
        "            self.decoders.append(self._conv_block(out_ch * 2, out_ch))\n",
        "        self.final_conv = nn.Sequential(nn.Conv2d(self.channels[0], self.channels[0] // 2, 3, padding=1), nn.BatchNorm2d(self.channels[0] // 2), nn.ReLU(inplace=True), nn.Conv2d(self.channels[0] // 2, 1, 1))\n",
        "    def _conv_block(self, in_ch, out_ch): return nn.Sequential(nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True), nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True))\n",
        "    def forward(self, x):\n",
        "        skips = []\n",
        "        for i in range(len(self.encoders)):\n",
        "            x = self.encoders[i](x); skips.append(x)\n",
        "            if i < len(self.downsamplers): x = self.downsamplers[i](x)\n",
        "        x = self.bottleneck(x)\n",
        "        if self.use_attention: x = self.attention(x)\n",
        "        for i, (up, dec) in enumerate(zip(self.upsamplers, self.decoders)):\n",
        "            x = up(x); skip = skips[len(skips) - 1 - i]\n",
        "            if x.shape[-2:] != skip.shape[-2:]: x = F.interpolate(x, size=skip.shape[-2:], mode='bilinear', align_corners=False)\n",
        "            x = torch.cat([x, skip], dim=1); x = dec(x)\n",
        "        return self.final_conv(x)\n",
        "\n",
        "class DiagnosticUNet(nn.Module): # Stage 2 Model\n",
        "    def __init__(self, input_channels=1, output_channels=1, base_channels=32, depth=3):\n",
        "        super().__init__()\n",
        "        self.channels = [base_channels * min(2**i, 8) for i in range(depth)]\n",
        "        self.encoders, self.downsamplers = nn.ModuleList(), nn.ModuleList()\n",
        "        in_ch = input_channels\n",
        "        for i, out_ch in enumerate(self.channels):\n",
        "            self.encoders.append(self._conv_block(in_ch, out_ch))\n",
        "            if i < len(self.channels) - 1: self.downsamplers.append(nn.Conv2d(out_ch, out_ch, 3, stride=2, padding=1))\n",
        "            in_ch = out_ch\n",
        "        bottleneck_ch = self.channels[-1]\n",
        "        self.bottleneck = self._conv_block(self.channels[-1], bottleneck_ch)\n",
        "        self.upsamplers, self.decoders = nn.ModuleList(), nn.ModuleList()\n",
        "        for i in range(depth - 1, -1, -1):\n",
        "            in_ch = bottleneck_ch if i == depth - 1 else self.channels[i+1]\n",
        "            out_ch = self.channels[i]\n",
        "            self.upsamplers.append(nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2))\n",
        "            self.decoders.append(self._conv_block(out_ch * 2, out_ch))\n",
        "        self.final_conv = nn.Conv2d(self.channels[0], output_channels, 1)\n",
        "    def _conv_block(self, in_ch, out_ch): return nn.Sequential(nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True), nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True))\n",
        "    def forward(self, x):\n",
        "        skips = []\n",
        "        for i in range(len(self.encoders)):\n",
        "            x = self.encoders[i](x); skips.append(x)\n",
        "            if i < len(self.downsamplers): x = self.downsamplers[i](x)\n",
        "        x = self.bottleneck(x)\n",
        "        for i, (up, dec) in enumerate(zip(self.upsamplers, self.decoders)):\n",
        "            x = up(x); skip = skips[len(skips) - 1 - i]\n",
        "            if x.shape[-2:] != skip.shape[-2:]: x = F.interpolate(x, size=skip.shape[-2:], mode='bilinear', align_corners=False)\n",
        "            x = torch.cat([x, skip], dim=1); x = dec(x)\n",
        "        return self.final_conv(x)\n",
        "\n",
        "# --- 3. HELPER FUNCTIONS ---\n",
        "def find_best_test_cases(dataset, threshold_k, num_cases):\n",
        "    scores = []\n",
        "    for i in tqdm(range(len(dataset)), desc=\"Finding best cases\"):\n",
        "        _, target_k_tensor, _ = dataset[i]\n",
        "        score = (target_k_tensor.numpy() <= threshold_k).sum()\n",
        "        scores.append((score, i))\n",
        "    scores.sort(key=lambda x: x[0], reverse=True)\n",
        "    return [idx for _, idx in scores[:num_cases]]\n",
        "\n",
        "# --- 4. VISUALIZATION FUNCTION ---\n",
        "def create_operational_figure(case_data, stage1_model, stage2_model, stats, device):\n",
        "    predictor_norm, _, case_name = case_data\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictor_subset = predictor_norm[VARIABLE_INDICES, :, :].unsqueeze(0).to(device)\n",
        "        stage1_pred_norm = stage1_model(predictor_subset)\n",
        "        stage2_pred_logits = stage2_model(stage1_pred_norm)\n",
        "        stage2_pred_prob = torch.sigmoid(stage2_pred_logits)\n",
        "\n",
        "    stage1_pred_k = stage1_pred_norm.cpu().numpy().squeeze() * (stats['target_std'] + 1e-8) + stats['target_mean']\n",
        "    threat_mask = stage2_pred_prob.cpu().numpy().squeeze()\n",
        "\n",
        "    # --- KEY CHANGE: Create a two-panel figure ---\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 7), facecolor='white')\n",
        "    fig.suptitle(f'Operational Forecast for Case: {case_name}', fontsize=20, fontweight='bold')\n",
        "\n",
        "    norm = colors.PowerNorm(gamma=0.4, vmin=200, vmax=275)\n",
        "\n",
        "    # Panel A: Stage 1 Forecast\n",
        "    axes[0].imshow(stage1_pred_k, cmap=COLORMAP, norm=norm)\n",
        "    axes[0].set_title('A) Stage 1: Quantitative TBB Forecast', fontsize=16)\n",
        "\n",
        "    # Panel B: Final Operational Product\n",
        "    axes[1].imshow(stage1_pred_k, cmap=COLORMAP, norm=norm)\n",
        "    # Use a threshold on the probability map for a cleaner overlay\n",
        "    axes[1].imshow(threat_mask, cmap='Reds', alpha=(threat_mask > 0.5) * 0.7, vmin=0, vmax=1)\n",
        "    axes[1].set_title('B) Final Product: Threat Highlight', fontsize=16)\n",
        "\n",
        "    for ax in axes:\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "\n",
        "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    save_path = OUTPUT_DIR / f\"operational_figure_{case_name}.png\"\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"✅ Saved operational figure to {save_path}\")\n",
        "\n",
        "# --- 5. MAIN SCRIPT ---\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # --- Load Models ---\n",
        "    stage1_model = FlexibleAblationModel(input_channels=INPUT_CHANNELS).to(device)\n",
        "    stage1_model.load_state_dict(torch.load(STAGE_1_MODEL_PATH, map_location=device))\n",
        "    stage1_model.eval()\n",
        "    print(f\"✅ Loaded Stage 1 Model: {STAGE_1_MODEL_PATH.name}\")\n",
        "\n",
        "    stage2_model = DiagnosticUNet().to(device)\n",
        "    stage2_model.load_state_dict(torch.load(STAGE_2_MODEL_PATH, map_location=device))\n",
        "    stage2_model.eval()\n",
        "    print(f\"✅ Loaded Stage 2 Model: {STAGE_2_MODEL_PATH.name}\")\n",
        "\n",
        "    # --- Find and Visualize Best Cases ---\n",
        "    test_dataset = MultiVariableARDataset(DATA_DIR, 'test')\n",
        "    best_case_indices = find_best_test_cases(test_dataset, DIAGNOSTIC_THRESHOLD_K, NUM_CASES_TO_PLOT)\n",
        "\n",
        "    print(f\"\\nGenerating {len(best_case_indices)} operational visualizations...\")\n",
        "    for idx in best_case_indices:\n",
        "        case_data = test_dataset[idx]\n",
        "        create_operational_figure(case_data, stage1_model, stage2_model, test_dataset.stats, device)\n",
        "\n",
        "    print(\"\\n🎉 Final visualization complete!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64xUwvA_F0Tg",
        "outputId": "f492f56f-d424-4089-83d9-aeafe14ec177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded Stage 1 Model: ablation_remove_IVT.pt\n",
            "✅ Loaded Stage 2 Model: best_diagnostic_model.pt\n",
            "Loaded 'test' dataset with 150 samples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Finding best cases: 100%|██████████| 150/150 [00:01<00:00, 101.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating 3 operational visualizations...\n",
            "✅ Saved operational figure to /content/drive/My Drive/AR_Downscaling/final_publication_figures/operational_figure_20230807_1200.png\n",
            "✅ Saved operational figure to /content/drive/My Drive/AR_Downscaling/final_publication_figures/operational_figure_20230615_1800.png\n",
            "✅ Saved operational figure to /content/drive/My Drive/AR_Downscaling/final_publication_figures/operational_figure_20230807_1800.png\n",
            "\n",
            "🎉 Final visualization complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# This script performs the final, comprehensive evaluation of the complete\n",
        "# two-stage \"Forecast and Diagnose\" pipeline against the Stage 1 baseline.\n",
        "#\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import joblib\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "PROJECT_PATH = Path('/content/drive/My Drive/AR_Downscaling')\n",
        "DATA_DIR = PROJECT_PATH / 'final_dataset_multi_variable'\n",
        "ABLATION_MODEL_DIR = PROJECT_PATH / 'ablation_study_models'\n",
        "DIAGNOSTIC_MODEL_DIR = PROJECT_PATH / 'final_diagnostic_model'\n",
        "OUTPUT_DIR = PROJECT_PATH / 'final_evaluation_results'\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# --- Models to Evaluate ---\n",
        "STAGE_1_MODEL_PATH = ABLATION_MODEL_DIR / 'ablation_remove_IVT.pt'\n",
        "STAGE_2_MODEL_PATH = DIAGNOSTIC_MODEL_DIR / 'best_diagnostic_model.pt'\n",
        "\n",
        "# --- Evaluation Configuration ---\n",
        "CSI_THRESHOLDS_K = [230.0, 220.0, 210.0]\n",
        "\n",
        "# --- Model & Data Configuration ---\n",
        "ALL_VARIABLES = ['IVT', 'T500', 'T850', 'RH700', 'W500']\n",
        "VARIABLES_TO_USE = ['T500', 'T850', 'RH700', 'W500']\n",
        "VARIABLE_INDICES = [ALL_VARIABLES.index(v) for v in VARIABLES_TO_USE]\n",
        "INPUT_CHANNELS = len(VARIABLE_INDICES)\n",
        "\n",
        "# --- 2. DATASET & MODEL ARCHITECTURES ---\n",
        "class MultiVariableARDataset(Dataset):\n",
        "    def __init__(self, data_dir: Path, split: str = 'test'):\n",
        "        self.split_dir = data_dir / split\n",
        "        self.predictor_files = sorted(list(self.split_dir.glob('*_predictor.npy')))\n",
        "        self.stats = joblib.load(data_dir / 'normalization_stats_multi_variable.joblib')\n",
        "        if not self.predictor_files: raise FileNotFoundError(f\"No predictor files in {self.split_dir}\")\n",
        "        print(f\"Loaded '{split}' dataset with {len(self.predictor_files)} samples.\")\n",
        "\n",
        "    def __len__(self): return len(self.predictor_files)\n",
        "    def __getitem__(self, idx):\n",
        "        pred_path = self.predictor_files[idx]\n",
        "        targ_path = Path(str(pred_path).replace('_predictor.npy', '_target.npy'))\n",
        "        predictor_data = np.load(pred_path).astype(np.float32)\n",
        "        target_data = np.load(targ_path).astype(np.float32)\n",
        "        predictor_norm = (predictor_data - self.stats['predictor_mean'][:, None, None]) / (self.stats['predictor_std'][:, None, None] + 1e-8)\n",
        "        # Return the unnormalized target for creating the ground truth mask\n",
        "        return torch.from_numpy(predictor_norm), torch.from_numpy(target_data)\n",
        "\n",
        "class SimplifiedAttention(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.channel_att = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Conv2d(channels, channels // 16, 1), nn.ReLU(inplace=True), nn.Conv2d(channels // 16, channels, 1), nn.Sigmoid())\n",
        "        self.spatial_att = nn.Sequential(nn.Conv2d(channels, 1, 7, padding=3), nn.Sigmoid())\n",
        "    def forward(self, x):\n",
        "        ch_att = self.channel_att(x); x = x * ch_att; sp_att = self.spatial_att(x); x = x * sp_att\n",
        "        return x\n",
        "\n",
        "class FlexibleAblationModel(nn.Module): # Stage 1 Model\n",
        "    def __init__(self, input_channels, base_channels=64, depth=4, use_attention=True):\n",
        "        super().__init__()\n",
        "        self.use_attention, self.depth = use_attention, depth\n",
        "        self.channels = [base_channels * min(2**i, 8) for i in range(depth)]\n",
        "        self.encoders, self.downsamplers = nn.ModuleList(), nn.ModuleList()\n",
        "        in_ch = input_channels\n",
        "        for i, out_ch in enumerate(self.channels):\n",
        "            self.encoders.append(self._conv_block(in_ch, out_ch))\n",
        "            if i < len(self.channels) - 1: self.downsamplers.append(nn.Conv2d(out_ch, out_ch, 3, stride=2, padding=1))\n",
        "            in_ch = out_ch\n",
        "        bottleneck_ch = self.channels[-1]\n",
        "        self.bottleneck = self._conv_block(self.channels[-1], bottleneck_ch)\n",
        "        if self.use_attention: self.attention = SimplifiedAttention(bottleneck_ch)\n",
        "        self.upsamplers, self.decoders = nn.ModuleList(), nn.ModuleList()\n",
        "        for i in range(depth - 1, -1, -1):\n",
        "            in_ch = bottleneck_ch if i == depth - 1 else self.channels[i+1]\n",
        "            out_ch = self.channels[i]\n",
        "            self.upsamplers.append(nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2))\n",
        "            self.decoders.append(self._conv_block(out_ch * 2, out_ch))\n",
        "        self.final_conv = nn.Sequential(nn.Conv2d(self.channels[0], self.channels[0] // 2, 3, padding=1), nn.BatchNorm2d(self.channels[0] // 2), nn.ReLU(inplace=True), nn.Conv2d(self.channels[0] // 2, 1, 1))\n",
        "    def _conv_block(self, in_ch, out_ch): return nn.Sequential(nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True), nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True))\n",
        "    def forward(self, x):\n",
        "        skips = []\n",
        "        for i in range(len(self.encoders)):\n",
        "            x = self.encoders[i](x); skips.append(x)\n",
        "            if i < len(self.downsamplers): x = self.downsamplers[i](x)\n",
        "        x = self.bottleneck(x)\n",
        "        if self.use_attention: x = self.attention(x)\n",
        "        for i, (up, dec) in enumerate(zip(self.upsamplers, self.decoders)):\n",
        "            x = up(x); skip = skips[len(skips) - 1 - i]\n",
        "            if x.shape[-2:] != skip.shape[-2:]: x = F.interpolate(x, size=skip.shape[-2:], mode='bilinear', align_corners=False)\n",
        "            x = torch.cat([x, skip], dim=1); x = dec(x)\n",
        "        return self.final_conv(x)\n",
        "\n",
        "class DiagnosticUNet(nn.Module): # Stage 2 Model\n",
        "    def __init__(self, input_channels=1, output_channels=1, base_channels=32, depth=3):\n",
        "        super().__init__()\n",
        "        self.channels = [base_channels * min(2**i, 8) for i in range(depth)]\n",
        "        self.encoders, self.downsamplers = nn.ModuleList(), nn.ModuleList()\n",
        "        in_ch = input_channels\n",
        "        for i, out_ch in enumerate(self.channels):\n",
        "            self.encoders.append(self._conv_block(in_ch, out_ch))\n",
        "            if i < len(self.channels) - 1: self.downsamplers.append(nn.Conv2d(out_ch, out_ch, 3, stride=2, padding=1))\n",
        "            in_ch = out_ch\n",
        "        bottleneck_ch = self.channels[-1]\n",
        "        self.bottleneck = self._conv_block(self.channels[-1], bottleneck_ch)\n",
        "        self.upsamplers, self.decoders = nn.ModuleList(), nn.ModuleList()\n",
        "        for i in range(depth - 1, -1, -1):\n",
        "            in_ch = bottleneck_ch if i == depth - 1 else self.channels[i+1]\n",
        "            out_ch = self.channels[i]\n",
        "            self.upsamplers.append(nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2))\n",
        "            self.decoders.append(self._conv_block(out_ch * 2, out_ch))\n",
        "        self.final_conv = nn.Conv2d(self.channels[0], output_channels, 1)\n",
        "    def _conv_block(self, in_ch, out_ch): return nn.Sequential(nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True), nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True))\n",
        "    def forward(self, x):\n",
        "        skips = []\n",
        "        for i in range(len(self.encoders)):\n",
        "            x = self.encoders[i](x); skips.append(x)\n",
        "            if i < len(self.downsamplers): x = self.downsamplers[i](x)\n",
        "        x = self.bottleneck(x)\n",
        "        for i, (up, dec) in enumerate(zip(self.upsamplers, self.decoders)):\n",
        "            x = up(x); skip = skips[len(skips) - 1 - i]\n",
        "            if x.shape[-2:] != skip.shape[-2:]: x = F.interpolate(x, size=skip.shape[-2:], mode='bilinear', align_corners=False)\n",
        "            x = torch.cat([x, skip], dim=1); x = dec(x)\n",
        "        return self.final_conv(x)\n",
        "\n",
        "# --- 3. METRIC FUNCTIONS ---\n",
        "def calculate_csi(pred_mask, true_mask):\n",
        "    hits = (pred_mask & true_mask).sum()\n",
        "    misses = (~pred_mask & true_mask).sum()\n",
        "    false_alarms = (pred_mask & ~true_mask).sum()\n",
        "    return hits / (hits + misses + false_alarms) if (hits + misses + false_alarms) > 0 else 0.0\n",
        "\n",
        "# --- 4. MAIN EVALUATION SCRIPT ---\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"🔧 Starting final evaluation on device: {device}\")\n",
        "\n",
        "    test_dataset = MultiVariableARDataset(DATA_DIR, 'test')\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "    stats = test_dataset.stats\n",
        "\n",
        "    stage1_model = FlexibleAblationModel(input_channels=INPUT_CHANNELS).to(device)\n",
        "    stage1_model.load_state_dict(torch.load(STAGE_1_MODEL_PATH, map_location=device))\n",
        "    stage1_model.eval()\n",
        "\n",
        "    stage2_model = DiagnosticUNet().to(device)\n",
        "    stage2_model.load_state_dict(torch.load(STAGE_2_MODEL_PATH, map_location=device))\n",
        "    stage2_model.eval()\n",
        "\n",
        "    stage1_metrics_list = []\n",
        "    final_pipeline_metrics_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for predictor_norm, target_k_tensor in tqdm(test_loader, desc=\"Evaluating Test Set\"):\n",
        "            predictor_subset = predictor_norm[:, VARIABLE_INDICES, :, :].to(device)\n",
        "            target_k = target_k_tensor.numpy().squeeze()\n",
        "\n",
        "            # --- Stage 1 Evaluation ---\n",
        "            stage1_pred_norm = stage1_model(predictor_subset)\n",
        "            stage1_pred_k = stage1_pred_norm.cpu().numpy().squeeze() * (stats['target_std'] + 1e-8) + stats['target_mean']\n",
        "\n",
        "            s1_metrics = {}\n",
        "            for thr in CSI_THRESHOLDS_K:\n",
        "                s1_pred_mask = stage1_pred_k <= thr\n",
        "                s1_true_mask = target_k <= thr\n",
        "                s1_metrics[f'csi_{int(thr)}K'] = calculate_csi(s1_pred_mask, s1_true_mask)\n",
        "            stage1_metrics_list.append(s1_metrics)\n",
        "\n",
        "            # --- Stage 2 / Final Pipeline Evaluation ---\n",
        "            stage2_pred_logits = stage2_model(stage1_pred_norm)\n",
        "            stage2_pred_mask = (torch.sigmoid(stage2_pred_logits) > 0.5).cpu().numpy().squeeze()\n",
        "\n",
        "            final_metrics = {}\n",
        "            for thr in CSI_THRESHOLDS_K:\n",
        "                # The final product's \"prediction\" is the mask from Stage 2\n",
        "                final_true_mask = target_k <= thr\n",
        "                # We assume the diagnostic model was trained for 220K, so its mask is the prediction for all thresholds\n",
        "                final_metrics[f'csi_{int(thr)}K'] = calculate_csi(stage2_pred_mask, final_true_mask)\n",
        "            final_pipeline_metrics_list.append(final_metrics)\n",
        "\n",
        "    # --- Reporting ---\n",
        "    stage1_df = pd.DataFrame(stage1_metrics_list).mean().add_prefix('Stage1_')\n",
        "    final_df = pd.DataFrame(final_pipeline_metrics_list).mean().add_prefix('Final_Pipeline_')\n",
        "\n",
        "    report_df = pd.concat([stage1_df, final_df], axis=1)\n",
        "\n",
        "    print(\"\\n\\n\" + \"=\"*80)\n",
        "    print(\"🏆 FINAL PIPELINE EVALUATION REPORT 🏆\")\n",
        "    print(\"=\"*80)\n",
        "    print(report_df.round(4))\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Calculate and print the percentage improvement\n",
        "    print(\"\\n--- CSI Improvement from Stage 2 Diagnosis ---\")\n",
        "    for thr in CSI_THRESHOLDS_K:\n",
        "        s1_score = report_df.loc[f'Stage1_csi_{int(thr)}K'][0]\n",
        "        final_score = report_df.loc[f'Final_Pipeline_csi_{int(thr)}K'][1]\n",
        "        if s1_score > 0:\n",
        "            improvement = ((final_score - s1_score) / s1_score) * 100\n",
        "            print(f\"  - CSI @ {int(thr)}K: {s1_score:.4f} -> {final_score:.4f} ({improvement:+.2f}%)\")\n",
        "        else:\n",
        "            print(f\"  - CSI @ {int(thr)}K: {s1_score:.4f} -> {final_score:.4f} (Improvement cannot be calculated)\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "    report_df.to_csv(OUTPUT_DIR / 'final_pipeline_evaluation.csv')\n",
        "    print(f\"\\n💾 Detailed results saved to: {OUTPUT_DIR / 'final_pipeline_evaluation.csv'}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "1HiNw8Y1OHuw",
        "outputId": "0ec306d0-eb98-41f6-89da-bf3ee5135d0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Starting final evaluation on device: cuda\n",
            "Loaded 'test' dataset with 150 samples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Test Set: 100%|██████████| 150/150 [00:03<00:00, 39.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "================================================================================\n",
            "🏆 FINAL PIPELINE EVALUATION REPORT 🏆\n",
            "================================================================================\n",
            "                              0       1\n",
            "Stage1_csi_230K          0.4293     NaN\n",
            "Stage1_csi_220K          0.1607     NaN\n",
            "Stage1_csi_210K          0.0587     NaN\n",
            "Final_Pipeline_csi_230K     NaN  0.4922\n",
            "Final_Pipeline_csi_220K     NaN  0.1962\n",
            "Final_Pipeline_csi_210K     NaN  0.0626\n",
            "================================================================================\n",
            "\n",
            "--- CSI Improvement from Stage 2 Diagnosis ---\n",
            "  - CSI @ 230K: 0.4293 -> 0.4922 (+14.65%)\n",
            "  - CSI @ 220K: 0.1607 -> 0.1962 (+22.12%)\n",
            "  - CSI @ 210K: 0.0587 -> 0.0626 (+6.76%)\n",
            "\n",
            "================================================================================\n",
            "\n",
            "💾 Detailed results saved to: /content/drive/My Drive/AR_Downscaling/final_evaluation_results/final_pipeline_evaluation.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}