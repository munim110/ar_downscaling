{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNPd5zV7PkuF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler, Dataset\n",
        "from pathlib import Path\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import joblib\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- DATASET AND MODEL DEFINITIONS (SELF-CONTAINED) ---\n",
        "\n",
        "class MultiVariableARDataset(Dataset):\n",
        "    \"\"\" The dataset class provided in your code. \"\"\"\n",
        "    def __init__(self, data_dir: Path, split: str = 'train'):\n",
        "        self.split_dir = data_dir / split\n",
        "        self.predictor_files = sorted(list(self.split_dir.glob('*_predictor.npy')))\n",
        "        self.stats = joblib.load(data_dir / 'normalization_stats_multi_variable.joblib')\n",
        "        if not self.predictor_files: raise FileNotFoundError(f\"No predictor files in {self.split_dir}\")\n",
        "\n",
        "    def __len__(self): return len(self.predictor_files)\n",
        "    def __getitem__(self, idx):\n",
        "        pred_path = self.predictor_files[idx]\n",
        "        targ_path = Path(str(pred_path).replace('_predictor.npy', '_target.npy'))\n",
        "        predictor_data = np.load(pred_path).astype(np.float32)\n",
        "        target_data = np.load(targ_path).astype(np.float32)\n",
        "        predictor_norm = (predictor_data - self.stats['predictor_mean'][:, None, None]) / (self.stats['predictor_std'][:, None, None] + 1e-8)\n",
        "        target_norm = (target_data - self.stats['target_mean']) / (self.stats['target_std'] + 1e-8)\n",
        "        return torch.from_numpy(predictor_norm), torch.from_numpy(target_norm).unsqueeze(0)\n",
        "\n",
        "class SimplifiedAttention(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.channel_att = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Conv2d(channels, channels // 16, 1), nn.ReLU(inplace=True), nn.Conv2d(channels // 16, channels, 1), nn.Sigmoid())\n",
        "        self.spatial_att = nn.Sequential(nn.Conv2d(channels, 1, 7, padding=3), nn.Sigmoid())\n",
        "    def forward(self, x):\n",
        "        ch_att = self.channel_att(x); x = x * ch_att; sp_att = self.spatial_att(x); x = x * sp_att\n",
        "        return x\n",
        "\n",
        "class AttentionUNet(nn.Module):\n",
        "    \"\"\" The Attention U-Net from your architecture study. \"\"\"\n",
        "    def __init__(self, input_channels=4, base_channels=64, depth=4, use_attention=True):\n",
        "        super().__init__()\n",
        "        self.use_attention, self.depth = use_attention, depth\n",
        "        self.channels = [base_channels * min(2**i, 8) for i in range(depth)]\n",
        "        self.encoders, self.downsamplers = nn.ModuleList(), nn.ModuleList()\n",
        "        in_ch = input_channels\n",
        "        for i, out_ch in enumerate(self.channels):\n",
        "            self.encoders.append(self._conv_block(in_ch, out_ch))\n",
        "            if i < len(self.channels) - 1: self.downsamplers.append(nn.Conv2d(out_ch, out_ch, 3, stride=2, padding=1))\n",
        "            in_ch = out_ch\n",
        "        bottleneck_ch = self.channels[-1]\n",
        "        self.bottleneck = self._conv_block(self.channels[-1], bottleneck_ch)\n",
        "        if self.use_attention: self.attention = SimplifiedAttention(bottleneck_ch)\n",
        "        self.upsamplers, self.decoders = nn.ModuleList(), nn.ModuleList()\n",
        "        for i in range(depth - 1, -1, -1):\n",
        "            in_ch = bottleneck_ch if i == depth - 1 else self.channels[i+1]\n",
        "            out_ch = self.channels[i]\n",
        "            self.upsamplers.append(nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2))\n",
        "            self.decoders.append(self._conv_block(out_ch * 2, out_ch))\n",
        "        self.final_conv = nn.Sequential(nn.Conv2d(self.channels[0], self.channels[0] // 2, 3, padding=1), nn.BatchNorm2d(self.channels[0] // 2), nn.ReLU(inplace=True), nn.Conv2d(self.channels[0] // 2, 1, 1))\n",
        "    def _conv_block(self, in_ch, out_ch): return nn.Sequential(nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True), nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True))\n",
        "    def forward(self, x):\n",
        "        skips = []; x_orig = x\n",
        "        for i in range(len(self.encoders)):\n",
        "            x = self.encoders[i](x); skips.append(x)\n",
        "            if i < len(self.downsamplers): x = self.downsamplers[i](x)\n",
        "        x = self.bottleneck(x)\n",
        "        if self.use_attention: x = self.attention(x)\n",
        "        for i, (up, dec) in enumerate(zip(self.upsamplers, self.decoders)):\n",
        "            x = up(x); skip = skips[len(skips) - 1 - i]\n",
        "            if x.shape[-2:] != skip.shape[-2:]: x = F.interpolate(x, size=skip.shape[-2:], mode='bilinear', align_corners=False)\n",
        "            x = torch.cat([x, skip], dim=1); x = dec(x)\n",
        "        return self.final_conv(x)\n",
        "\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "PROJECT_PATH = Path('/content/drive/My Drive/AR_Downscaling')\n",
        "DATA_DIR = PROJECT_PATH / 'final_dataset_multi_variable'\n",
        "OUTPUT_DIR = PROJECT_PATH / 'publication_experiments' / 'attention_unet_final'\n",
        "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
        "MODEL_SAVE_PATH = OUTPUT_DIR / 'attention_unet_final_model.pth'\n",
        "WEIGHTS_SAVE_PATH = PROJECT_PATH / 'hip_eef_smart_sampling_model' / 'sampler_weights.pt'\n",
        "\n",
        "# --- Training Hyperparameters ---\n",
        "EPOCHS = 50; BATCH_SIZE = 8; LEARNING_RATE = 1e-4; EARLY_STOPPING_PATIENCE = 10; GRADIENT_CLIP = 1.0\n",
        "\n",
        "# --- Variable & Loss Configuration ---\n",
        "ALL_VARIABLES = ['IVT', 'T500', 'T850', 'RH700', 'W500']\n",
        "VARIABLE_NAMES = ['T500', 'T850', 'RH700', 'W500']\n",
        "VARIABLE_INDICES = [ALL_VARIABLES.index(v) for v in VARIABLE_NAMES]\n",
        "INPUT_CHANNELS = len(VARIABLE_INDICES)\n",
        "LOSS_THRESHOLDS = { 220.0: 10.0, 210.0: 25.0 }\n",
        "SAMPLING_WEIGHT_THRESHOLD = 220.0\n",
        "\n",
        "# --- 2. TIERED WEIGHTED LOSS ---\n",
        "class TieredWeightedMSELoss(nn.Module):\n",
        "    def __init__(self, thresholds: dict):\n",
        "        super().__init__()\n",
        "        self.thresholds = sorted(thresholds.items(), key=lambda item: item[0])\n",
        "        self.mse = nn.MSELoss(reduction='none')\n",
        "\n",
        "    def forward(self, prediction_norm, target_norm, stats):\n",
        "        loss = self.mse(prediction_norm, target_norm)\n",
        "        with torch.no_grad():\n",
        "            target_k = target_norm * (stats['target_std'] + 1e-8) + stats['target_mean']\n",
        "            weights = torch.ones_like(target_k)\n",
        "            for temp_k, weight in self.thresholds:\n",
        "                weights[target_k <= temp_k] = weight\n",
        "        return torch.mean(loss * weights)\n",
        "\n",
        "# --- 3. SAMPLER WEIGHT CALCULATION ---\n",
        "def get_sampler_weights(dataset, stats):\n",
        "    if WEIGHTS_SAVE_PATH.exists():\n",
        "        print(f\"Loading cached sampler weights from {WEIGHTS_SAVE_PATH}\")\n",
        "        return torch.load(WEIGHTS_SAVE_PATH)\n",
        "    # This part of the code will not be reached if weights exist\n",
        "    print(\"Pre-computing sampler weights...\"); weights = []\n",
        "    for _, target_norm in tqdm(dataset):\n",
        "        target_k = target_norm.numpy().squeeze() * (stats['target_std'] + 1e-8) + stats['target_mean']\n",
        "        percentage = np.mean(target_k <= SAMPLING_WEIGHT_THRESHOLD); weights.append(0.1 + percentage)\n",
        "    weights = torch.tensor(weights, dtype=torch.float); torch.save(weights, WEIGHTS_SAVE_PATH)\n",
        "    return weights\n",
        "\n",
        "# --- 4. MAIN TRAINING SCRIPT ---\n",
        "def train_dl_baseline():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"--- Training Strongest DL Baseline (Attention U-Net) with Smart Sampling ---\")\n",
        "\n",
        "    train_dataset = MultiVariableARDataset(DATA_DIR, 'train')\n",
        "    val_dataset = MultiVariableARDataset(DATA_DIR, 'val')\n",
        "    sampler_weights = get_sampler_weights(train_dataset, train_dataset.stats)\n",
        "    sampler = WeightedRandomSampler(sampler_weights, num_samples=len(sampler_weights), replacement=True)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    model = AttentionUNet(input_channels=INPUT_CHANNELS).to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
        "    criterion = TieredWeightedMSELoss(thresholds=LOSS_THRESHOLDS)\n",
        "    print(f\"Training with TieredWeightedMSELoss.\")\n",
        "\n",
        "    best_val_loss = float('inf'); patience_counter = 0\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\")\n",
        "\n",
        "        # *** KEY FIX: Unpack only 2 items from the DataLoader ***\n",
        "        for predictor, target_norm in pbar:\n",
        "            predictor_subset = predictor[:, VARIABLE_INDICES, :, :].to(device)\n",
        "            target_norm = target_norm.to(device)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "                prediction_norm = model(predictor_subset)\n",
        "                loss = criterion(prediction_norm, target_norm, train_dataset.stats)\n",
        "            scaler.scale(loss).backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIP)\n",
        "            scaler.step(optimizer); scaler.update()\n",
        "            pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "        model.eval()\n",
        "        val_total_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            # *** KEY FIX: Unpack only 2 items in the validation loop as well ***\n",
        "            for predictor, target_norm in val_loader:\n",
        "                predictor_subset = predictor[:, VARIABLE_INDICES, :, :].to(device)\n",
        "                target_norm = target_norm.to(device)\n",
        "                prediction_norm = model(predictor_subset)\n",
        "                loss = criterion(prediction_norm, target_norm, val_dataset.stats)\n",
        "                val_total_loss += loss.item()\n",
        "        avg_val_loss = val_total_loss / len(val_loader)\n",
        "        print(f\"Epoch {epoch+1} | Validation Loss: {avg_val_loss:.6f}\")\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "            print(f\"   ✅ Best model saved to {MODEL_SAVE_PATH}\")\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "        if patience_counter >= EARLY_STOPPING_PATIENCE:\n",
        "            print(f\"   🛑 Early stopping triggered.\"); break\n",
        "\n",
        "    print(f\"\\n--- ✅ Strong DL Baseline Training Finished. Best Validation Loss: {best_val_loss:.6f} ---\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_dl_baseline()\n"
      ]
    }
  ]
}