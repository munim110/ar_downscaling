{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qYmeJMVCYPG",
        "outputId": "d16aef93-8d80-4329-866a-e67c0d0595e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Starting evaluation on device: cuda\n",
            "Loaded 'test' dataset with 150 samples.\n",
            "\n",
            "--- Evaluating all_variables (5 variables) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting with all_variables: 100%|██████████| 150/150 [01:57<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating pair_IVT_RH700 (2 variables) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting with pair_IVT_RH700: 100%|██████████| 150/150 [00:16<00:00,  9.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating pair_IVT_T500 (2 variables) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting with pair_IVT_T500: 100%|██████████| 150/150 [00:15<00:00,  9.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating pair_IVT_W500 (2 variables) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting with pair_IVT_W500: 100%|██████████| 150/150 [00:17<00:00,  8.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating pair_RH700_W500 (2 variables) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting with pair_RH700_W500: 100%|██████████| 150/150 [00:16<00:00,  8.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating pair_T500_T850 (2 variables) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting with pair_T500_T850: 100%|██████████| 150/150 [00:16<00:00,  8.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating pair_T500_W500 (2 variables) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting with pair_T500_W500: 100%|██████████| 150/150 [00:16<00:00,  9.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating remove_IVT (4 variables) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting with remove_IVT: 100%|██████████| 150/150 [00:16<00:00,  8.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating remove_RH700 (4 variables) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting with remove_RH700: 100%|██████████| 150/150 [00:15<00:00,  9.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating remove_T500 (4 variables) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting with remove_T500: 100%|██████████| 150/150 [00:14<00:00, 10.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating remove_T850 (4 variables) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting with remove_T850: 100%|██████████| 150/150 [00:16<00:00,  9.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating remove_W500 (4 variables) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting with remove_W500: 100%|██████████| 150/150 [00:16<00:00,  9.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating single_IVT (1 variables) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting with single_IVT: 100%|██████████| 150/150 [00:15<00:00,  9.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating single_RH700 (1 variables) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting with single_RH700: 100%|██████████| 150/150 [00:14<00:00, 10.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating single_T500 (1 variables) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting with single_T500: 100%|██████████| 150/150 [00:16<00:00,  9.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating single_T850 (1 variables) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting with single_T850: 100%|██████████| 150/150 [00:14<00:00, 10.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating single_W500 (1 variables) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting with single_W500: 100%|██████████| 150/150 [00:15<00:00,  9.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating triplet_IVT_RH700_W500 (3 variables) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting with triplet_IVT_RH700_W500: 100%|██████████| 150/150 [00:15<00:00,  9.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating triplet_IVT_T500_RH700 (3 variables) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting with triplet_IVT_T500_RH700: 100%|██████████| 150/150 [00:15<00:00,  9.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating triplet_IVT_T500_W500 (3 variables) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting with triplet_IVT_T500_W500: 100%|██████████| 150/150 [00:16<00:00,  8.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating triplet_T500_T850_W500 (3 variables) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting with triplet_T500_T850_W500: 100%|██████████| 150/150 [00:15<00:00,  9.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "================================================================================\n",
            "🔬 FINAL ABLATION STUDY EVALUATION REPORT 🔬\n",
            "================================================================================\n",
            "\n",
            "--- Performance Ranking (Sorted by CSI @ 220K) ---\n",
            "                        Input Channels  csi_230K_mean  csi_220K_mean  \\\n",
            "Model                                                                  \n",
            "pair_T500_W500                       2         0.4115         0.1756   \n",
            "single_T500                          1         0.4247         0.1696   \n",
            "remove_IVT                           4         0.4293         0.1607   \n",
            "remove_T500                          4         0.4456         0.1511   \n",
            "triplet_T500_T850_W500               3         0.4189         0.1231   \n",
            "remove_T850                          4         0.4152         0.1181   \n",
            "triplet_IVT_T500_W500                3         0.4201         0.0843   \n",
            "triplet_IVT_RH700_W500               3         0.4429         0.0671   \n",
            "single_W500                          1         0.4008         0.0578   \n",
            "pair_IVT_RH700                       2         0.4351         0.0499   \n",
            "remove_W500                          4         0.4266         0.0442   \n",
            "all_variables                        5         0.4312         0.0433   \n",
            "remove_RH700                         4         0.4005         0.0408   \n",
            "pair_RH700_W500                      2         0.4281         0.0298   \n",
            "pair_IVT_T500                        2         0.4122         0.0295   \n",
            "pair_IVT_W500                        2         0.3923         0.0286   \n",
            "single_IVT                           1         0.4354         0.0094   \n",
            "triplet_IVT_T500_RH700               3         0.4244         0.0022   \n",
            "single_RH700                         1         0.4122         0.0002   \n",
            "pair_T500_T850                       2         0.4188         0.0000   \n",
            "single_T850                          1         0.4257         0.0000   \n",
            "\n",
            "                        csi_210K_mean  rmse_mean  sharpness_mean  \n",
            "Model                                                             \n",
            "pair_T500_W500                 0.0583     9.3252          1.3515  \n",
            "single_T500                    0.0003    10.5983          0.9489  \n",
            "remove_IVT                     0.0587     9.0806          1.2599  \n",
            "remove_T500                    0.0465    12.7767          2.2882  \n",
            "triplet_T500_T850_W500         0.0069     8.4708          0.8860  \n",
            "remove_T850                    0.0009     8.7580          0.8596  \n",
            "triplet_IVT_T500_W500          0.0000     8.8440          0.8114  \n",
            "triplet_IVT_RH700_W500         0.0029     8.7916          1.0362  \n",
            "single_W500                    0.0010     8.6595          0.7693  \n",
            "pair_IVT_RH700                 0.0001     9.1514          1.0702  \n",
            "remove_W500                    0.0001     8.6723          0.7353  \n",
            "all_variables                  0.0026     8.6517          0.7837  \n",
            "remove_RH700                   0.0008     8.9131          1.0784  \n",
            "pair_RH700_W500                0.0007     8.5785          0.9164  \n",
            "pair_IVT_T500                  0.0000     8.7860          0.6402  \n",
            "pair_IVT_W500                  0.0000     8.9212          0.7759  \n",
            "single_IVT                     0.0000     8.7569          0.4917  \n",
            "triplet_IVT_T500_RH700         0.0000     8.7294          0.6379  \n",
            "single_RH700                   0.0000     8.8144          0.8033  \n",
            "pair_T500_T850                 0.0000     8.9109          0.5155  \n",
            "single_T850                    0.0000     9.1535          0.5632  \n",
            "\n",
            "--- Variable Importance Analysis (Based on 'Leave-One-Out' models) ---\n",
            "Performance Drop (%) when variable is REMOVED (Higher = More Important):\n",
            "  - RH700: 5.79%\n",
            "  - W500: -2.08%\n",
            "  - T850: -172.35%\n",
            "  - T500: -248.65%\n",
            "  - IVT: -270.66%\n",
            "\n",
            "================================================================================\n",
            "\n",
            "💾 Detailed results saved to: /content/drive/My Drive/AR_Downscaling/final_evaluation_results/ablation_study_evaluation.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# This script performs a comprehensive, quantitative evaluation comparing the\n",
        "# results of the ablation study to determine variable importance.\n",
        "#\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import joblib\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from scipy.stats import wasserstein_distance\n",
        "from scipy.ndimage import sobel\n",
        "import json\n",
        "import math\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "PROJECT_PATH = Path('/content/drive/My Drive/AR_Downscaling')\n",
        "DATA_DIR = PROJECT_PATH / 'final_dataset_multi_variable'\n",
        "MODEL_DIR = PROJECT_PATH / 'ablation_study_models' # Directory where ablation models were saved\n",
        "OUTPUT_DIR = PROJECT_PATH / 'final_evaluation_results'\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# --- Evaluation Configuration ---\n",
        "CSI_THRESHOLDS_K = [230.0, 220.0, 210.0]\n",
        "ALL_VARIABLES = ['IVT', 'T500', 'T850', 'RH700', 'W500']\n",
        "\n",
        "# --- 2. DATASET & MODEL ARCHITECTURES ---\n",
        "class MultiVariableARDataset(Dataset):\n",
        "    \"\"\"Loads the full 5-channel dataset for evaluation.\"\"\"\n",
        "    def __init__(self, data_dir: Path, split: str = 'test'):\n",
        "        self.split_dir = data_dir / split\n",
        "        self.predictor_files = sorted(list(self.split_dir.glob('*_predictor.npy')))\n",
        "        self.stats = joblib.load(data_dir / 'normalization_stats_multi_variable.joblib')\n",
        "        if not self.predictor_files: raise FileNotFoundError(f\"No predictor files in {self.split_dir}\")\n",
        "        print(f\"Loaded '{split}' dataset with {len(self.predictor_files)} samples.\")\n",
        "\n",
        "    def __len__(self): return len(self.predictor_files)\n",
        "    def __getitem__(self, idx):\n",
        "        pred_path = self.predictor_files[idx]\n",
        "        targ_path = Path(str(pred_path).replace('_predictor.npy', '_target.npy'))\n",
        "        predictor_data = np.load(pred_path).astype(np.float32)\n",
        "        target_data = np.load(targ_path).astype(np.float32)\n",
        "        predictor_norm = (predictor_data - self.stats['predictor_mean'][:, None, None]) / (self.stats['predictor_std'][:, None, None] + 1e-8)\n",
        "        target_norm = (target_data - self.stats['target_mean']) / (self.stats['target_std'] + 1e-8)\n",
        "        return torch.from_numpy(predictor_norm), torch.from_numpy(target_norm).unsqueeze(0)\n",
        "\n",
        "class SimplifiedAttention(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.channel_att = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Conv2d(channels, channels // 16, 1), nn.ReLU(inplace=True), nn.Conv2d(channels // 16, channels, 1), nn.Sigmoid())\n",
        "        self.spatial_att = nn.Sequential(nn.Conv2d(channels, 1, 7, padding=3), nn.Sigmoid())\n",
        "    def forward(self, x):\n",
        "        ch_att = self.channel_att(x); x = x * ch_att; sp_att = self.spatial_att(x); x = x * sp_att\n",
        "        return x\n",
        "\n",
        "class FlexibleAblationModel(nn.Module):\n",
        "    \"\"\"The Regression Baseline model, adapted to accept any number of input channels.\"\"\"\n",
        "    def __init__(self, input_channels, base_channels=64, depth=4, use_attention=True):\n",
        "        super().__init__()\n",
        "        self.use_attention, self.depth = use_attention, depth\n",
        "        self.channels = [base_channels * min(2**i, 8) for i in range(depth)]\n",
        "        self.encoders, self.downsamplers = nn.ModuleList(), nn.ModuleList()\n",
        "        in_ch = input_channels\n",
        "        for i, out_ch in enumerate(self.channels):\n",
        "            self.encoders.append(self._conv_block(in_ch, out_ch))\n",
        "            if i < len(self.channels) - 1: self.downsamplers.append(nn.Conv2d(out_ch, out_ch, 3, stride=2, padding=1))\n",
        "            in_ch = out_ch\n",
        "        bottleneck_ch = self.channels[-1]\n",
        "        self.bottleneck = self._conv_block(self.channels[-1], bottleneck_ch)\n",
        "        if self.use_attention: self.attention = SimplifiedAttention(bottleneck_ch)\n",
        "        self.upsamplers, self.decoders = nn.ModuleList(), nn.ModuleList()\n",
        "        for i in range(depth - 1, -1, -1):\n",
        "            in_ch = bottleneck_ch if i == depth - 1 else self.channels[i+1]\n",
        "            out_ch = self.channels[i]\n",
        "            self.upsamplers.append(nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2))\n",
        "            self.decoders.append(self._conv_block(out_ch * 2, out_ch))\n",
        "        self.final_conv = nn.Sequential(nn.Conv2d(self.channels[0], self.channels[0] // 2, 3, padding=1), nn.BatchNorm2d(self.channels[0] // 2), nn.ReLU(inplace=True), nn.Conv2d(self.channels[0] // 2, 1, 1))\n",
        "    def _conv_block(self, in_ch, out_ch): return nn.Sequential(nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True), nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True))\n",
        "    def forward(self, x):\n",
        "        skips = []\n",
        "        for i in range(len(self.encoders)):\n",
        "            x = self.encoders[i](x); skips.append(x)\n",
        "            if i < len(self.downsamplers): x = self.downsamplers[i](x)\n",
        "        x = self.bottleneck(x)\n",
        "        if self.use_attention: x = self.attention(x)\n",
        "        for i, (up, dec) in enumerate(zip(self.upsamplers, self.decoders)):\n",
        "            x = up(x); skip = skips[len(skips) - 1 - i]\n",
        "            if x.shape[-2:] != skip.shape[-2:]: x = F.interpolate(x, size=skip.shape[-2:], mode='bilinear', align_corners=False)\n",
        "            x = torch.cat([x, skip], dim=1); x = dec(x)\n",
        "        return self.final_conv(x)\n",
        "\n",
        "# --- 3. METRIC FUNCTIONS ---\n",
        "def calculate_detailed_csi(pred_k, true_k, threshold_k):\n",
        "    pred_mask = pred_k <= threshold_k; true_mask = true_k <= threshold_k\n",
        "    hits = (pred_mask & true_mask).sum()\n",
        "    misses = (~pred_mask & true_mask).sum()\n",
        "    false_alarms = (pred_mask & ~true_mask).sum()\n",
        "    csi = hits / (hits + misses + false_alarms) if (hits + misses + false_alarms) > 0 else 0.0\n",
        "    event_frequency = true_mask.sum() / true_mask.size\n",
        "    return csi, event_frequency\n",
        "\n",
        "def calculate_gradient_magnitude(image):\n",
        "    grad_x = sobel(image, axis=0); grad_y = sobel(image, axis=1)\n",
        "    return np.sqrt(grad_x**2 + grad_y**2).mean()\n",
        "\n",
        "def calculate_all_metrics(pred_norm, true_norm, stats):\n",
        "    pred_k = pred_norm * (stats['target_std'] + 1e-8) + stats['target_mean']\n",
        "    true_k = true_norm * (stats['target_std'] + 1e-8) + stats['target_mean']\n",
        "    metrics = {\n",
        "        'rmse': np.sqrt(np.mean((pred_k - true_k)**2)),\n",
        "        'mae': np.mean(np.abs(pred_k - true_k)),\n",
        "        'sharpness': calculate_gradient_magnitude(pred_k),\n",
        "        'distribution_dist': wasserstein_distance(pred_k.flatten(), true_k.flatten())\n",
        "    }\n",
        "    for thr in CSI_THRESHOLDS_K:\n",
        "        csi, freq = calculate_detailed_csi(pred_k, true_k, thr)\n",
        "        metrics[f'csi_{int(thr)}K'] = csi\n",
        "        metrics[f'freq_{int(thr)}K'] = freq\n",
        "    return metrics\n",
        "\n",
        "# --- 4. MAIN EVALUATION SCRIPT ---\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"🔧 Starting evaluation on device: {device}\")\n",
        "\n",
        "    test_dataset = MultiVariableARDataset(DATA_DIR, 'test')\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "    stats = test_dataset.stats\n",
        "\n",
        "    # --- Find and Load Models Automatically ---\n",
        "    metadata_files = sorted(list(MODEL_DIR.glob('ablation_*.json')))\n",
        "    if not metadata_files:\n",
        "        print(f\"❌ No model metadata files found in {MODEL_DIR}. Cannot evaluate.\")\n",
        "        return\n",
        "\n",
        "    all_results = []\n",
        "    for meta_file in metadata_files:\n",
        "        with open(meta_file, 'r') as f:\n",
        "            metadata = json.load(f)\n",
        "\n",
        "        name = metadata['name']\n",
        "        variables = metadata['variables']\n",
        "        variable_indices = [ALL_VARIABLES.index(v) for v in variables]\n",
        "        input_channels = len(variable_indices)\n",
        "        model_path = meta_file.with_suffix('.pt')\n",
        "\n",
        "        if not model_path.exists():\n",
        "            print(f\"⚠️ Model file not found for '{name}'. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n--- Evaluating {name} ({input_channels} variables) ---\")\n",
        "        model = FlexibleAblationModel(input_channels=input_channels).to(device)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "        model.eval()\n",
        "\n",
        "        model_metrics = []\n",
        "        with torch.no_grad():\n",
        "            for predictor, target in tqdm(test_loader, desc=f\"Predicting with {name}\"):\n",
        "                # Select the correct variable subset for the model\n",
        "                predictor_subset = predictor[:, variable_indices, :, :].to(device)\n",
        "\n",
        "                pred_norm = model(predictor_subset).cpu().numpy().squeeze()\n",
        "                target_norm = target.numpy().squeeze()\n",
        "                metrics = calculate_all_metrics(pred_norm, target_norm, stats)\n",
        "                model_metrics.append(metrics)\n",
        "\n",
        "        df = pd.DataFrame(model_metrics)\n",
        "        summary = {\"Model\": name, \"Input Channels\": input_channels, \"Variables\": \", \".join(variables)}\n",
        "        for col in df.columns:\n",
        "            summary[f\"{col}_mean\"] = df[col].mean()\n",
        "            summary[f\"{col}_std\"] = df[col].std()\n",
        "        all_results.append(summary)\n",
        "\n",
        "    if not all_results:\n",
        "        print(\"❌ No models were evaluated. Exiting.\")\n",
        "        return\n",
        "\n",
        "    results_df = pd.DataFrame(all_results).set_index(\"Model\")\n",
        "\n",
        "    # --- Reporting ---\n",
        "    print(\"\\n\\n\" + \"=\"*80)\n",
        "    print(\"🔬 FINAL ABLATION STUDY EVALUATION REPORT 🔬\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Sort by the most critical CSI score for ranking\n",
        "    results_df = results_df.sort_values(by='csi_220K_mean', ascending=False)\n",
        "\n",
        "    print(\"\\n--- Performance Ranking (Sorted by CSI @ 220K) ---\")\n",
        "    report_cols = ['Input Channels', 'csi_230K_mean', 'csi_220K_mean', 'csi_210K_mean', 'rmse_mean', 'sharpness_mean']\n",
        "    print(results_df[report_cols].round(4))\n",
        "\n",
        "    print(\"\\n--- Variable Importance Analysis (Based on 'Leave-One-Out' models) ---\")\n",
        "    control_model_csi = results_df.loc['all_variables']['csi_220K_mean']\n",
        "    importance = {}\n",
        "    for var in ALL_VARIABLES:\n",
        "        model_name = f'remove_{var}'\n",
        "        if model_name in results_df.index:\n",
        "            model_csi = results_df.loc[model_name]['csi_220K_mean']\n",
        "            performance_drop = (control_model_csi - model_csi) / control_model_csi\n",
        "            importance[var] = performance_drop * 100\n",
        "\n",
        "    print(\"Performance Drop (%) when variable is REMOVED (Higher = More Important):\")\n",
        "    for var, drop in sorted(importance.items(), key=lambda item: item[1], reverse=True):\n",
        "        print(f\"  - {var}: {drop:.2f}%\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "    results_df.to_csv(OUTPUT_DIR / 'ablation_study_evaluation.csv')\n",
        "    print(f\"\\n💾 Detailed results saved to: {OUTPUT_DIR / 'ablation_study_evaluation.csv'}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}