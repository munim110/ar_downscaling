{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtLSpreP2LJ9",
        "outputId": "d57a725b-a0a0-4ac1-9591-f08ae552ca2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "üéØ Starting Comprehensive Test Set Evaluation\n",
            "============================================================\n",
            "üìä Test dataset: 150 samples\n",
            "üîß Using device: cuda\n",
            "üîç Found 29 trained models:\n",
            "   - arch_original_unet: Architecture: original_unet\n",
            "   - arch_resnet_unet: Architecture: resnet_unet\n",
            "   - arch_attention_unet: Architecture: attention_unet\n",
            "   - arch_lightweight_cnn: Architecture: lightweight_cnn\n",
            "   - single_IVT: Variables: single_IVT\n",
            "   - single_T500: Variables: single_T500\n",
            "   - single_T850: Variables: single_T850\n",
            "   - single_RH700: Variables: single_RH700\n",
            "   - single_W500: Variables: single_W500\n",
            "   - pair_IVT_T500: Variables: pair_IVT_T500\n",
            "   - pair_IVT_RH700: Variables: pair_IVT_RH700\n",
            "   - pair_T500_T850: Variables: pair_T500_T850\n",
            "   - pair_RH700_W500: Variables: pair_RH700_W500\n",
            "   - pair_IVT_W500: Variables: pair_IVT_W500\n",
            "   - pair_T500_W500: Variables: pair_T500_W500\n",
            "   - triplet_IVT_T500_RH700: Variables: triplet_IVT_T500_RH700\n",
            "   - triplet_T500_T850_W500: Variables: triplet_T500_T850_W500\n",
            "   - triplet_IVT_RH700_W500: Variables: triplet_IVT_RH700_W500\n",
            "   - triplet_IVT_T500_W500: Variables: triplet_IVT_T500_W500\n",
            "   - remove_IVT: Variables: remove_IVT\n",
            "   - remove_T500: Variables: remove_T500\n",
            "   - remove_T850: Variables: remove_T850\n",
            "   - remove_RH700: Variables: remove_RH700\n",
            "   - remove_W500: Variables: remove_W500\n",
            "   - all_variables: Variables: all_variables\n",
            "   - no_gan_baseline_epoch_10: No GAN Baseline 10\n",
            "   - no_gan_baseline_epoch_20: No GAN Baseline 20\n",
            "   - no_gan_baseline_epoch_25: No GAN Baseline 25\n",
            "   - fair_baseline: Fair Baseline (From Scratch)\n",
            "üéØ Evaluating arch_original_unet...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating arch_original_unet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:21<00:00,  7.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ arch_original_unet completed\n",
            "   RMSE: 8.501 ¬± 3.308\n",
            "   CSI: 0.142 ¬± 0.171\n",
            "   FSS: 0.398 ¬± 0.351\n",
            "üéØ Evaluating arch_resnet_unet...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating arch_resnet_unet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:06<00:00, 23.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ arch_resnet_unet completed\n",
            "   RMSE: 8.241 ¬± 3.349\n",
            "   CSI: 0.088 ¬± 0.138\n",
            "   FSS: 0.327 ¬± 0.370\n",
            "üéØ Evaluating arch_attention_unet...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating arch_attention_unet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 37.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ arch_attention_unet completed\n",
            "   RMSE: 8.220 ¬± 3.217\n",
            "   CSI: 0.126 ¬± 0.172\n",
            "   FSS: 0.384 ¬± 0.368\n",
            "üéØ Evaluating arch_lightweight_cnn...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating arch_lightweight_cnn: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 42.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ arch_lightweight_cnn completed\n",
            "   RMSE: 8.664 ¬± 3.514\n",
            "   CSI: 0.103 ¬± 0.137\n",
            "   FSS: 0.332 ¬± 0.345\n",
            "üéØ Evaluating single_IVT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating single_IVT: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 42.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ single_IVT completed\n",
            "   RMSE: 8.939 ¬± 3.413\n",
            "   CSI: 0.030 ¬± 0.060\n",
            "   FSS: 0.238 ¬± 0.367\n",
            "üéØ Evaluating single_T500...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating single_T500: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 43.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ single_T500 completed\n",
            "   RMSE: 10.083 ¬± 4.124\n",
            "   CSI: 0.014 ¬± 0.033\n",
            "   FSS: 0.032 ¬± 0.068\n",
            "üéØ Evaluating single_T850...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating single_T850: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 43.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ single_T850 completed\n",
            "   RMSE: 11.142 ¬± 4.476\n",
            "   CSI: 0.000 ¬± 0.000\n",
            "   FSS: 0.173 ¬± 0.379\n",
            "üéØ Evaluating single_RH700...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating single_RH700: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 43.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ single_RH700 completed\n",
            "   RMSE: 10.594 ¬± 4.395\n",
            "   CSI: 0.000 ¬± 0.001\n",
            "   FSS: 0.174 ¬± 0.378\n",
            "üéØ Evaluating single_W500...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating single_W500: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 41.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ single_W500 completed\n",
            "   RMSE: 12.636 ¬± 6.018\n",
            "   CSI: 0.000 ¬± 0.000\n",
            "   FSS: 0.173 ¬± 0.379\n",
            "üéØ Evaluating pair_IVT_T500...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating pair_IVT_T500: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 41.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ pair_IVT_T500 completed\n",
            "   RMSE: 8.660 ¬± 3.220\n",
            "   CSI: 0.047 ¬± 0.074\n",
            "   FSS: 0.269 ¬± 0.360\n",
            "üéØ Evaluating pair_IVT_RH700...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating pair_IVT_RH700: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 37.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ pair_IVT_RH700 completed\n",
            "   RMSE: 8.698 ¬± 3.042\n",
            "   CSI: 0.063 ¬± 0.098\n",
            "   FSS: 0.293 ¬± 0.361\n",
            "üéØ Evaluating pair_T500_T850...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating pair_T500_T850: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 43.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ pair_T500_T850 completed\n",
            "   RMSE: 10.229 ¬± 4.165\n",
            "   CSI: 0.002 ¬± 0.009\n",
            "   FSS: 0.177 ¬± 0.377\n",
            "üéØ Evaluating pair_RH700_W500...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating pair_RH700_W500: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 41.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ pair_RH700_W500 completed\n",
            "   RMSE: 10.444 ¬± 3.945\n",
            "   CSI: 0.001 ¬± 0.010\n",
            "   FSS: 0.176 ¬± 0.378\n",
            "üéØ Evaluating pair_IVT_W500...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating pair_IVT_W500: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 42.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ pair_IVT_W500 completed\n",
            "   RMSE: 10.373 ¬± 3.956\n",
            "   CSI: 0.000 ¬± 0.001\n",
            "   FSS: 0.160 ¬± 0.367\n",
            "üéØ Evaluating pair_T500_W500...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating pair_T500_W500: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 39.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ pair_T500_W500 completed\n",
            "   RMSE: 11.496 ¬± 4.263\n",
            "   CSI: 0.000 ¬± 0.003\n",
            "   FSS: 0.154 ¬± 0.360\n",
            "üéØ Evaluating triplet_IVT_T500_RH700...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating triplet_IVT_T500_RH700: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 37.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ triplet_IVT_T500_RH700 completed\n",
            "   RMSE: 8.815 ¬± 3.234\n",
            "   CSI: 0.036 ¬± 0.066\n",
            "   FSS: 0.246 ¬± 0.365\n",
            "üéØ Evaluating triplet_T500_T850_W500...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating triplet_T500_T850_W500: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 41.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ triplet_T500_T850_W500 completed\n",
            "   RMSE: 11.056 ¬± 4.699\n",
            "   CSI: 0.000 ¬± 0.000\n",
            "   FSS: 0.153 ¬± 0.360\n",
            "üéØ Evaluating triplet_IVT_RH700_W500...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating triplet_IVT_RH700_W500: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 42.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ triplet_IVT_RH700_W500 completed\n",
            "   RMSE: 8.718 ¬± 3.430\n",
            "   CSI: 0.001 ¬± 0.009\n",
            "   FSS: 0.176 ¬± 0.378\n",
            "üéØ Evaluating triplet_IVT_T500_W500...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating triplet_IVT_T500_W500: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 43.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ triplet_IVT_T500_W500 completed\n",
            "   RMSE: 9.945 ¬± 4.292\n",
            "   CSI: 0.000 ¬± 0.000\n",
            "   FSS: 0.153 ¬± 0.360\n",
            "üéØ Evaluating remove_IVT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating remove_IVT: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 41.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ remove_IVT completed\n",
            "   RMSE: 9.496 ¬± 3.853\n",
            "   CSI: 0.006 ¬± 0.031\n",
            "   FSS: 0.152 ¬± 0.347\n",
            "üéØ Evaluating remove_T500...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating remove_T500: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:04<00:00, 35.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ remove_T500 completed\n",
            "   RMSE: 9.636 ¬± 3.904\n",
            "   CSI: 0.001 ¬± 0.005\n",
            "   FSS: 0.168 ¬± 0.372\n",
            "üéØ Evaluating remove_T850...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating remove_T850: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 40.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ remove_T850 completed\n",
            "   RMSE: 9.182 ¬± 3.601\n",
            "   CSI: 0.001 ¬± 0.010\n",
            "   FSS: 0.176 ¬± 0.378\n",
            "üéØ Evaluating remove_RH700...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating remove_RH700: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 42.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ remove_RH700 completed\n",
            "   RMSE: 10.599 ¬± 4.240\n",
            "   CSI: 0.001 ¬± 0.012\n",
            "   FSS: 0.109 ¬± 0.309\n",
            "üéØ Evaluating remove_W500...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating remove_W500: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 40.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ remove_W500 completed\n",
            "   RMSE: 8.761 ¬± 3.504\n",
            "   CSI: 0.013 ¬± 0.030\n",
            "   FSS: 0.201 ¬± 0.371\n",
            "üéØ Evaluating all_variables...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating all_variables: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 41.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ all_variables completed\n",
            "   RMSE: 8.373 ¬± 3.337\n",
            "   CSI: 0.108 ¬± 0.152\n",
            "   FSS: 0.362 ¬± 0.366\n",
            "üéØ Evaluating no_gan_baseline_epoch_10...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating no_gan_baseline_epoch_10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 37.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ no_gan_baseline_epoch_10 completed\n",
            "   RMSE: 8.386 ¬± 3.220\n",
            "   CSI: 0.046 ¬± 0.095\n",
            "   FSS: 0.257 ¬± 0.374\n",
            "üéØ Evaluating no_gan_baseline_epoch_20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating no_gan_baseline_epoch_20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 41.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ no_gan_baseline_epoch_20 completed\n",
            "   RMSE: 8.294 ¬± 3.198\n",
            "   CSI: 0.079 ¬± 0.135\n",
            "   FSS: 0.311 ¬± 0.374\n",
            "üéØ Evaluating no_gan_baseline_epoch_25...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating no_gan_baseline_epoch_25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:04<00:00, 35.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ no_gan_baseline_epoch_25 completed\n",
            "   RMSE: 8.288 ¬± 3.157\n",
            "   CSI: 0.091 ¬± 0.157\n",
            "   FSS: 0.325 ¬± 0.381\n",
            "üéØ Evaluating fair_baseline...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating fair_baseline: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 43.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ fair_baseline completed\n",
            "   RMSE: 8.417 ¬± 3.745\n",
            "   CSI: 0.117 ¬± 0.152\n",
            "   FSS: 0.373 ¬± 0.358\n",
            "üéØ Evaluating transfer_learning_gan...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating transfer_learning_gan: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 38.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ transfer_learning_gan completed\n",
            "   RMSE: 8.411 ¬± 3.189\n",
            "   CSI: 0.148 ¬± 0.174\n",
            "   FSS: 0.416 ¬± 0.350\n",
            "üéØ Evaluating transfer_learning_gan...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating transfer_learning_gan: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 42.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ transfer_learning_gan completed\n",
            "   RMSE: 8.246 ¬± 3.127\n",
            "   CSI: 0.115 ¬± 0.157\n",
            "   FSS: 0.372 ¬± 0.365\n",
            "üéØ Evaluating transfer_learning_gan...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating transfer_learning_gan: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 43.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ transfer_learning_gan completed\n",
            "   RMSE: 8.234 ¬± 2.978\n",
            "   CSI: 0.110 ¬± 0.151\n",
            "   FSS: 0.357 ¬± 0.361\n",
            "üéØ Evaluating transfer_learning_gan...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating transfer_learning_gan: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 42.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ transfer_learning_gan completed\n",
            "   RMSE: 8.250 ¬± 3.135\n",
            "   CSI: 0.108 ¬± 0.170\n",
            "   FSS: 0.351 ¬± 0.380\n",
            "üéØ Evaluating transfer_learning_gan...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating transfer_learning_gan: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:03<00:00, 38.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ transfer_learning_gan completed\n",
            "   RMSE: 8.348 ¬± 3.011\n",
            "   CSI: 0.147 ¬± 0.176\n",
            "   FSS: 0.412 ¬± 0.353\n",
            "\n",
            "üìä Successfully evaluated 34 models\n",
            "\n",
            "üèÜ Model Performance Ranking (by CSI):\n",
            "================================================================================\n",
            " Rank                    Model          Category                       Description  Channels           RMSE           CSI           FSS          SSIM\n",
            "    1    transfer_learning_gan transfer_learning           Transfer Learning GAN 5         5  8.411 ¬± 3.189 0.148 ¬± 0.174 0.416 ¬± 0.350 0.630 ¬± 0.111\n",
            "    2    transfer_learning_gan transfer_learning          Transfer Learning GAN 25         5  8.348 ¬± 3.011 0.147 ¬± 0.176 0.412 ¬± 0.353 0.621 ¬± 0.105\n",
            "    3       arch_original_unet      architecture       Architecture: original_unet         5  8.501 ¬± 3.308 0.142 ¬± 0.171 0.398 ¬± 0.351 0.637 ¬± 0.120\n",
            "    4      arch_attention_unet      architecture      Architecture: attention_unet         5  8.220 ¬± 3.217 0.126 ¬± 0.172 0.384 ¬± 0.368 0.651 ¬± 0.115\n",
            "    5            fair_baseline          baseline      Fair Baseline (From Scratch)         5  8.417 ¬± 3.745 0.117 ¬± 0.152 0.373 ¬± 0.358 0.636 ¬± 0.123\n",
            "    6    transfer_learning_gan transfer_learning          Transfer Learning GAN 10         5  8.246 ¬± 3.127 0.115 ¬± 0.157 0.372 ¬± 0.365 0.649 ¬± 0.114\n",
            "    7    transfer_learning_gan transfer_learning          Transfer Learning GAN 15         5  8.234 ¬± 2.978 0.110 ¬± 0.151 0.357 ¬± 0.361 0.635 ¬± 0.109\n",
            "    8            all_variables          ablation          Variables: all_variables         5  8.373 ¬± 3.337 0.108 ¬± 0.152 0.362 ¬± 0.366 0.642 ¬± 0.117\n",
            "    9    transfer_learning_gan transfer_learning          Transfer Learning GAN 20         5  8.250 ¬± 3.135 0.108 ¬± 0.170 0.351 ¬± 0.380 0.650 ¬± 0.111\n",
            "   10     arch_lightweight_cnn      architecture     Architecture: lightweight_cnn         5  8.664 ¬± 3.514 0.103 ¬± 0.137 0.332 ¬± 0.345 0.629 ¬± 0.115\n",
            "   11 no_gan_baseline_epoch_25          baseline                No GAN Baseline 25         5  8.288 ¬± 3.157 0.091 ¬± 0.157 0.325 ¬± 0.381 0.667 ¬± 0.114\n",
            "   12         arch_resnet_unet      architecture         Architecture: resnet_unet         5  8.241 ¬± 3.349 0.088 ¬± 0.138 0.327 ¬± 0.370 0.654 ¬± 0.118\n",
            "   13 no_gan_baseline_epoch_20          baseline                No GAN Baseline 20         5  8.294 ¬± 3.198 0.079 ¬± 0.135 0.311 ¬± 0.374 0.666 ¬± 0.115\n",
            "   14           pair_IVT_RH700          ablation         Variables: pair_IVT_RH700         2  8.698 ¬± 3.042 0.063 ¬± 0.098 0.293 ¬± 0.361 0.633 ¬± 0.106\n",
            "   15            pair_IVT_T500          ablation          Variables: pair_IVT_T500         2  8.660 ¬± 3.220 0.047 ¬± 0.074 0.269 ¬± 0.360 0.602 ¬± 0.126\n",
            "   16 no_gan_baseline_epoch_10          baseline                No GAN Baseline 10         5  8.386 ¬± 3.220 0.046 ¬± 0.095 0.257 ¬± 0.374 0.666 ¬± 0.113\n",
            "   17   triplet_IVT_T500_RH700          ablation Variables: triplet_IVT_T500_RH700         3  8.815 ¬± 3.234 0.036 ¬± 0.066 0.246 ¬± 0.365 0.653 ¬± 0.119\n",
            "   18               single_IVT          ablation             Variables: single_IVT         1  8.939 ¬± 3.413 0.030 ¬± 0.060 0.238 ¬± 0.367 0.497 ¬± 0.126\n",
            "   19              single_T500          ablation            Variables: single_T500         1 10.083 ¬± 4.124 0.014 ¬± 0.033 0.032 ¬± 0.068 0.596 ¬± 0.109\n",
            "   20              remove_W500          ablation            Variables: remove_W500         4  8.761 ¬± 3.504 0.013 ¬± 0.030 0.201 ¬± 0.371 0.650 ¬± 0.119\n",
            "   21               remove_IVT          ablation             Variables: remove_IVT         4  9.496 ¬± 3.853 0.006 ¬± 0.031 0.152 ¬± 0.347 0.653 ¬± 0.111\n",
            "   22           pair_T500_T850          ablation         Variables: pair_T500_T850         2 10.229 ¬± 4.165 0.002 ¬± 0.009 0.177 ¬± 0.377 0.602 ¬± 0.104\n",
            "   23          pair_RH700_W500          ablation        Variables: pair_RH700_W500         2 10.444 ¬± 3.945 0.001 ¬± 0.010 0.176 ¬± 0.378 0.642 ¬± 0.101\n",
            "   24              remove_T850          ablation            Variables: remove_T850         4  9.182 ¬± 3.601 0.001 ¬± 0.010 0.176 ¬± 0.378 0.660 ¬± 0.111\n",
            "   25   triplet_IVT_RH700_W500          ablation Variables: triplet_IVT_RH700_W500         3  8.718 ¬± 3.430 0.001 ¬± 0.009 0.176 ¬± 0.378 0.663 ¬± 0.112\n",
            "   26             remove_RH700          ablation           Variables: remove_RH700         4 10.599 ¬± 4.240 0.001 ¬± 0.012 0.109 ¬± 0.309 0.651 ¬± 0.107\n",
            "   27              remove_T500          ablation            Variables: remove_T500         4  9.636 ¬± 3.904 0.001 ¬± 0.005 0.168 ¬± 0.372 0.649 ¬± 0.110\n",
            "   28           pair_T500_W500          ablation         Variables: pair_T500_W500         2 11.496 ¬± 4.263 0.000 ¬± 0.003 0.154 ¬± 0.360 0.645 ¬± 0.108\n",
            "   29             single_RH700          ablation           Variables: single_RH700         1 10.594 ¬± 4.395 0.000 ¬± 0.001 0.174 ¬± 0.378 0.587 ¬± 0.123\n",
            "   30            pair_IVT_W500          ablation          Variables: pair_IVT_W500         2 10.373 ¬± 3.956 0.000 ¬± 0.001 0.160 ¬± 0.367 0.652 ¬± 0.106\n",
            "   31              single_T850          ablation            Variables: single_T850         1 11.142 ¬± 4.476 0.000 ¬± 0.000 0.173 ¬± 0.379 0.622 ¬± 0.104\n",
            "   32              single_W500          ablation            Variables: single_W500         1 12.636 ¬± 6.018 0.000 ¬± 0.000 0.173 ¬± 0.379 0.608 ¬± 0.110\n",
            "   33   triplet_T500_T850_W500          ablation Variables: triplet_T500_T850_W500         3 11.056 ¬± 4.699 0.000 ¬± 0.000 0.153 ¬± 0.360 0.642 ¬± 0.103\n",
            "   34    triplet_IVT_T500_W500          ablation  Variables: triplet_IVT_T500_W500         3  9.945 ¬± 4.292 0.000 ¬± 0.000 0.153 ¬± 0.360 0.654 ¬± 0.111\n",
            "\n",
            "üìà Analysis by Category:\n",
            "----------------------------------------\n",
            "\n",
            "ARCHITECTURE Models (4 models):\n",
            "  Best: arch_original_unet (CSI: 0.142)\n",
            "  Average CSI: 0.115\n",
            "  Average RMSE: 8.406\n",
            "\n",
            "ABLATION Models (21 models):\n",
            "  Best: all_variables (CSI: 0.108)\n",
            "  Average CSI: 0.015\n",
            "  Average RMSE: 9.899\n",
            "\n",
            "BASELINE Models (4 models):\n",
            "  Best: fair_baseline (CSI: 0.117)\n",
            "  Average CSI: 0.083\n",
            "  Average RMSE: 8.347\n",
            "\n",
            "TRANSFER_LEARNING Models (5 models):\n",
            "  Best: transfer_learning_gan (CSI: 0.148)\n",
            "  Average CSI: 0.126\n",
            "  Average RMSE: 8.298\n",
            "\n",
            "üíæ Results saved to /content/drive/My Drive/AR_Downscaling/final_evaluation_results\n",
            "\n",
            "üéâ Comprehensive evaluation completed!\n",
            "üìä Results and visualizations saved to: /content/drive/My Drive/AR_Downscaling/final_evaluation_results\n",
            "\n",
            "üèÜ Best Overall Model: transfer_learning_gan\n",
            "   Description: Transfer Learning GAN 5\n",
            "   CSI: 0.148\n",
            "   RMSE: 8.411\n"
          ]
        }
      ],
      "source": [
        "# --- COMPREHENSIVE TEST SET EVALUATION ---\n",
        "# This script loads ALL your trained models and evaluates them on the same test set\n",
        "# with consistent metrics for fair comparison\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from scipy import stats\n",
        "import json\n",
        "import joblib\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "PROJECT_PATH = Path('/content/drive/My Drive/AR_Downscaling')\n",
        "DATA_DIR = PROJECT_PATH / 'final_dataset_multi_variable'\n",
        "MODELS_DIR = PROJECT_PATH / 'publication_experiments'\n",
        "OUTPUT_DIR = PROJECT_PATH / 'final_evaluation_results'\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# --- DATASET CLASS ---\n",
        "class MultiVariableARDataset(Dataset):\n",
        "    def __init__(self, data_dir: Path, split: str = 'test'):\n",
        "        self.split_dir = data_dir / split\n",
        "        self.predictor_files = sorted(list(self.split_dir.glob('*_predictor.npy')))\n",
        "        self.stats = joblib.load(data_dir / 'normalization_stats_multi_variable.joblib')\n",
        "        if not self.predictor_files:\n",
        "            raise FileNotFoundError(f\"No predictor files in {self.split_dir}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.predictor_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pred_path = self.predictor_files[idx]\n",
        "        targ_path = Path(str(pred_path).replace('_predictor.npy', '_target.npy'))\n",
        "        predictor_data = np.load(pred_path).astype(np.float32)\n",
        "        target_data = np.load(targ_path).astype(np.float32)\n",
        "        # Normalize\n",
        "        predictor_data = (predictor_data - self.stats['predictor_mean'][:, None, None]) / (\n",
        "            self.stats['predictor_std'][:, None, None] + 1e-8)\n",
        "        target_data = (target_data - self.stats['target_mean']) / (self.stats['target_std'] + 1e-8)\n",
        "        return torch.from_numpy(predictor_data), torch.from_numpy(target_data).unsqueeze(0)\n",
        "\n",
        "# --- MODEL ARCHITECTURES (copied from your working code) ---\n",
        "class SimplifiedAttention(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.channel_att = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(channels, channels // 16, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(channels // 16, channels, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.spatial_att = nn.Sequential(\n",
        "            nn.Conv2d(channels, 1, 7, padding=3),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        ch_att = self.channel_att(x)\n",
        "        x = x * ch_att\n",
        "        sp_att = self.spatial_att(x)\n",
        "        x = x * sp_att\n",
        "        return x\n",
        "\n",
        "class MultiVariableGenerator(nn.Module):\n",
        "    def __init__(self, input_channels=5, base_channels=64, depth=4, use_attention=True):\n",
        "        super().__init__()\n",
        "        self.use_attention, self.depth = use_attention, depth\n",
        "        channels = [base_channels * min(2**i, 8) for i in range(depth)]\n",
        "\n",
        "        self.encoders, self.downsamplers = nn.ModuleList(), nn.ModuleList()\n",
        "        in_ch = input_channels\n",
        "        for i, out_ch in enumerate(channels):\n",
        "            self.encoders.append(self._conv_block(in_ch, out_ch))\n",
        "            if i < len(channels) - 1:\n",
        "                self.downsamplers.append(nn.Conv2d(out_ch, out_ch, 3, stride=2, padding=1))\n",
        "            in_ch = out_ch\n",
        "\n",
        "        bottleneck_ch = channels[-1]\n",
        "        self.bottleneck = self._conv_block(channels[-1], bottleneck_ch)\n",
        "        if self.use_attention:\n",
        "            self.attention = SimplifiedAttention(bottleneck_ch)\n",
        "\n",
        "        self.upsamplers, self.decoders = nn.ModuleList(), nn.ModuleList()\n",
        "        for i in range(depth-1, -1, -1):\n",
        "            in_ch = bottleneck_ch if i == depth-1 else channels[i+1]\n",
        "            out_ch = channels[i]\n",
        "            self.upsamplers.append(nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2))\n",
        "            self.decoders.append(self._conv_block(out_ch * 2, out_ch))\n",
        "\n",
        "        self.final_conv = nn.Sequential(nn.Conv2d(channels[0], 1, 1), nn.Tanh())\n",
        "\n",
        "    def _conv_block(self, in_ch, out_ch):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        skips = []\n",
        "        for i in range(len(self.encoders)):\n",
        "            x = self.encoders[i](x)\n",
        "            skips.append(x)\n",
        "            if i < len(self.downsamplers):\n",
        "                x = self.downsamplers[i](x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "        if self.use_attention:\n",
        "            x = self.attention(x)\n",
        "\n",
        "        for i, (up, dec) in enumerate(zip(self.upsamplers, self.decoders)):\n",
        "            x = up(x)\n",
        "            skip = skips[len(skips) - 1 - i]\n",
        "            if x.shape[-2:] != skip.shape[-2:]:\n",
        "                x = F.interpolate(x, size=skip.shape[-2:], mode='bilinear', align_corners=False)\n",
        "            x = torch.cat([x, skip], dim=1)\n",
        "            x = dec(x)\n",
        "\n",
        "        return self.final_conv(x)\n",
        "\n",
        "# ResNet, Attention, and Lightweight architectures (copy from your architecture code)\n",
        "class ResNetBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += identity\n",
        "        return self.relu(out)\n",
        "\n",
        "class ResNetUNet(nn.Module):\n",
        "    def __init__(self, input_channels=5, base_channels=64, depth=4):\n",
        "        super().__init__()\n",
        "        self.depth = depth\n",
        "        channels = [base_channels * min(2**i, 8) for i in range(depth)]\n",
        "        self.initial_conv = nn.Conv2d(input_channels, channels[0], 3, padding=1)\n",
        "        self.encoders, self.downsamplers = nn.ModuleList(), nn.ModuleList()\n",
        "\n",
        "        for i, ch in enumerate(channels):\n",
        "            self.encoders.append(nn.Sequential(ResNetBlock(ch), ResNetBlock(ch)))\n",
        "            if i < len(channels) - 1:\n",
        "                self.downsamplers.append(nn.Conv2d(ch, channels[i+1], 3, stride=2, padding=1))\n",
        "\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            ResNetBlock(channels[-1]), ResNetBlock(channels[-1]), ResNetBlock(channels[-1])\n",
        "        )\n",
        "\n",
        "        self.upsamplers, self.decoders = nn.ModuleList(), nn.ModuleList()\n",
        "        for i in range(depth-1, 0, -1):\n",
        "            self.upsamplers.append(nn.ConvTranspose2d(channels[i], channels[i-1], 2, stride=2))\n",
        "            self.decoders.append(nn.Sequential(\n",
        "                ResNetBlock(channels[i-1] * 2), ResNetBlock(channels[i-1] * 2),\n",
        "                nn.Conv2d(channels[i-1] * 2, channels[i-1], 1)\n",
        "            ))\n",
        "\n",
        "        self.final_conv = nn.Sequential(\n",
        "            nn.Conv2d(channels[0], channels[0]//2, 3, padding=1),\n",
        "            nn.BatchNorm2d(channels[0]//2), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(channels[0]//2, 1, 1), nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial_conv(x)\n",
        "        skips = []\n",
        "\n",
        "        for i, (encoder, downsampler) in enumerate(zip(self.encoders, self.downsamplers)):\n",
        "            x = encoder(x)\n",
        "            skips.append(x)\n",
        "            x = downsampler(x)\n",
        "\n",
        "        x = self.encoders[-1](x)\n",
        "        skips.append(x)\n",
        "        x = self.bottleneck(x)\n",
        "\n",
        "        for i, (upsampler, decoder) in enumerate(zip(self.upsamplers, self.decoders)):\n",
        "            x = upsampler(x)\n",
        "            skip = skips[len(skips) - 2 - i]\n",
        "            if x.shape[-2:] != skip.shape[-2:]:\n",
        "                x = F.interpolate(x, size=skip.shape[-2:], mode='bilinear', align_corners=False)\n",
        "            x = torch.cat([x, skip], dim=1)\n",
        "            x = decoder(x)\n",
        "\n",
        "        return self.final_conv(x)\n",
        "\n",
        "class AttentionUNet(nn.Module):\n",
        "    def __init__(self, input_channels=5, base_channels=64, depth=4):\n",
        "        super().__init__()\n",
        "        self.depth = depth\n",
        "        channels = [base_channels * min(2**i, 8) for i in range(depth)]\n",
        "\n",
        "        self.encoders, self.downsamplers = nn.ModuleList(), nn.ModuleList()\n",
        "        in_ch = input_channels\n",
        "        for i, out_ch in enumerate(channels):\n",
        "            self.encoders.append(self._conv_block(in_ch, out_ch))\n",
        "            if i < len(channels) - 1:\n",
        "                self.downsamplers.append(nn.Conv2d(out_ch, out_ch, 3, stride=2, padding=1))\n",
        "            in_ch = out_ch\n",
        "\n",
        "        bottleneck_ch = channels[-1]\n",
        "        self.bottleneck_conv = self._conv_block(bottleneck_ch, bottleneck_ch)\n",
        "        self.attention = SimplifiedAttention(bottleneck_ch)\n",
        "        self.bottleneck_final = self._conv_block(bottleneck_ch, bottleneck_ch)\n",
        "\n",
        "        self.upsamplers, self.decoders = nn.ModuleList(), nn.ModuleList()\n",
        "        for i in range(depth-1, -1, -1):\n",
        "            in_ch = bottleneck_ch if i == depth-1 else channels[i+1]\n",
        "            out_ch = channels[i]\n",
        "            self.upsamplers.append(nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2))\n",
        "            self.decoders.append(self._conv_block(out_ch * 2, out_ch))\n",
        "\n",
        "        self.final_conv = nn.Sequential(\n",
        "            nn.Conv2d(channels[0], channels[0]//2, 3, padding=1),\n",
        "            nn.BatchNorm2d(channels[0]//2), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(channels[0]//2, 1, 1), nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def _conv_block(self, in_ch, out_ch):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        skips = []\n",
        "        for i in range(len(self.encoders)):\n",
        "            x = self.encoders[i](x)\n",
        "            skips.append(x)\n",
        "            if i < len(self.downsamplers):\n",
        "                x = self.downsamplers[i](x)\n",
        "\n",
        "        x = self.bottleneck_conv(x)\n",
        "        x = self.attention(x)\n",
        "        x = self.bottleneck_final(x)\n",
        "\n",
        "        for i, (up, dec) in enumerate(zip(self.upsamplers, self.decoders)):\n",
        "            x = up(x)\n",
        "            skip = skips[len(skips) - 1 - i]\n",
        "            if x.shape[-2:] != skip.shape[-2:]:\n",
        "                x = F.interpolate(x, size=skip.shape[-2:], mode='bilinear', align_corners=False)\n",
        "            x = torch.cat([x, skip], dim=1)\n",
        "            x = dec(x)\n",
        "\n",
        "        return self.final_conv(x)\n",
        "\n",
        "class LightweightCNN(nn.Module):\n",
        "    def __init__(self, input_channels=5):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, 32, 7, padding=3), nn.BatchNorm2d(32), nn.ReLU(inplace=True), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 5, padding=2), nn.BatchNorm2d(64), nn.ReLU(inplace=True), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 1, 3, padding=1), nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        original_size = x.shape[-2:]\n",
        "        out = self.features(x)\n",
        "        if out.shape[-2:] != original_size:\n",
        "            out = F.interpolate(out, size=original_size, mode='bilinear', align_corners=False)\n",
        "        return out\n",
        "\n",
        "# --- FLEXIBLE DATASET FOR VARIABLE SUBSETS ---\n",
        "class FlexibleMultiVariableDataset(Dataset):\n",
        "    def __init__(self, data_dir: Path, split: str, variable_subset: list):\n",
        "        self.split_dir = data_dir / split\n",
        "        self.predictor_files = sorted(list(self.split_dir.glob('*_predictor.npy')))\n",
        "        self.variable_subset = variable_subset\n",
        "        self.variable_indices = [['IVT', 'T500', 'T850', 'RH700', 'W500'].index(var) for var in variable_subset]\n",
        "        self.stats = joblib.load(data_dir / 'normalization_stats_multi_variable.joblib')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.predictor_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pred_path = self.predictor_files[idx]\n",
        "        targ_path = Path(str(pred_path).replace('_predictor.npy', '_target.npy'))\n",
        "\n",
        "        full_predictor_data = np.load(pred_path).astype(np.float32)\n",
        "        target_data = np.load(targ_path).astype(np.float32)\n",
        "\n",
        "        predictor_data = full_predictor_data[self.variable_indices]\n",
        "\n",
        "        predictor_mean = self.stats['predictor_mean'][self.variable_indices, None, None]\n",
        "        predictor_std = self.stats['predictor_std'][self.variable_indices, None, None]\n",
        "\n",
        "        predictor_data = (predictor_data - predictor_mean) / (predictor_std + 1e-8)\n",
        "        target_data = (target_data - self.stats['target_mean']) / (self.stats['target_std'] + 1e-8)\n",
        "\n",
        "        return torch.from_numpy(predictor_data), torch.from_numpy(target_data).unsqueeze(0)\n",
        "\n",
        "# --- FLEXIBLE GENERATOR FOR ABLATION MODELS ---\n",
        "class FlexibleGenerator(nn.Module):\n",
        "    def __init__(self, input_channels, base_channels=64, depth=4, use_attention=True):\n",
        "        super().__init__()\n",
        "        self.use_attention, self.depth = use_attention, depth\n",
        "        channels = [base_channels * min(2**i, 8) for i in range(depth)]\n",
        "\n",
        "        self.encoders, self.downsamplers = nn.ModuleList(), nn.ModuleList()\n",
        "        in_ch = input_channels\n",
        "        for i, out_ch in enumerate(channels):\n",
        "            self.encoders.append(self._conv_block(in_ch, out_ch))\n",
        "            if i < len(channels) - 1:\n",
        "                self.downsamplers.append(nn.Conv2d(out_ch, out_ch, 3, stride=2, padding=1))\n",
        "            in_ch = out_ch\n",
        "\n",
        "        bottleneck_ch = channels[-1]\n",
        "        self.bottleneck = self._conv_block(channels[-1], bottleneck_ch)\n",
        "        if self.use_attention:\n",
        "            self.attention = SimplifiedAttention(bottleneck_ch)\n",
        "\n",
        "        self.upsamplers, self.decoders = nn.ModuleList(), nn.ModuleList()\n",
        "        for i in range(depth-1, -1, -1):\n",
        "            in_ch = bottleneck_ch if i == depth-1 else channels[i+1]\n",
        "            out_ch = channels[i]\n",
        "            self.upsamplers.append(nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2))\n",
        "            self.decoders.append(self._conv_block(out_ch * 2, out_ch))\n",
        "\n",
        "        self.final_conv = nn.Sequential(nn.Conv2d(channels[0], 1, 1), nn.Tanh())\n",
        "\n",
        "    def _conv_block(self, in_ch, out_ch):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        skips = []\n",
        "        for i in range(len(self.encoders)):\n",
        "            x = self.encoders[i](x)\n",
        "            skips.append(x)\n",
        "            if i < len(self.downsamplers):\n",
        "                x = self.downsamplers[i](x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "        if self.use_attention:\n",
        "            x = self.attention(x)\n",
        "\n",
        "        for i, (up, dec) in enumerate(zip(self.upsamplers, self.decoders)):\n",
        "            x = up(x)\n",
        "            skip = skips[len(skips) - 1 - i]\n",
        "            if x.shape[-2:] != skip.shape[-2:]:\n",
        "                x = F.interpolate(x, size=skip.shape[-2:], mode='bilinear', align_corners=False)\n",
        "            x = torch.cat([x, skip], dim=1)\n",
        "            x = dec(x)\n",
        "\n",
        "        return self.final_conv(x)\n",
        "\n",
        "# --- EVALUATION METRICS ---\n",
        "def denormalize(data, stats):\n",
        "    return data * (stats.get('target_std', 1.0) + 1e-8) + stats.get('target_mean', 0.0)\n",
        "\n",
        "def calculate_ssim(pred, target):\n",
        "    data_range = target.max() - target.min()\n",
        "    if data_range == 0:\n",
        "        return 1.0 if np.all(pred == target) else 0.0\n",
        "    return ssim(target, pred, data_range=data_range, win_size=7)\n",
        "\n",
        "def calculate_csi(pred, target, threshold=220.0):\n",
        "    pred_event = pred <= threshold\n",
        "    target_event = target <= threshold\n",
        "    hits = np.sum(pred_event & target_event)\n",
        "    misses = np.sum(~pred_event & target_event)\n",
        "    false_alarms = np.sum(pred_event & ~target_event)\n",
        "    return hits / (hits + misses + false_alarms) if (hits + misses + false_alarms) > 0 else 0.0\n",
        "\n",
        "def calculate_fss(pred, target, threshold=220.0, window_size=11):\n",
        "    from scipy.ndimage import uniform_filter\n",
        "    pred_binary = (pred <= threshold).astype(float)\n",
        "    target_binary = (target <= threshold).astype(float)\n",
        "    pred_fractions = uniform_filter(pred_binary, size=window_size)\n",
        "    target_fractions = uniform_filter(target_binary, size=window_size)\n",
        "    mse_fractions = np.mean((pred_fractions - target_fractions) ** 2)\n",
        "    mse_fractions_ref = np.mean(pred_fractions ** 2) + np.mean(target_fractions ** 2)\n",
        "    return 1 - (mse_fractions / mse_fractions_ref) if mse_fractions_ref > 0 else 1.0\n",
        "\n",
        "def calculate_all_metrics(pred, target, stats):\n",
        "    # Denormalize for physical metrics\n",
        "    pred_dn = denormalize(pred, stats)\n",
        "    target_dn = denormalize(target, stats)\n",
        "\n",
        "    return {\n",
        "        'rmse': np.sqrt(mean_squared_error(target_dn.flatten(), pred_dn.flatten())),\n",
        "        'mae': mean_absolute_error(target_dn.flatten(), pred_dn.flatten()),\n",
        "        'r2': r2_score(target_dn.flatten(), pred_dn.flatten()),\n",
        "        'correlation': np.corrcoef(target_dn.flatten(), pred_dn.flatten())[0, 1],\n",
        "        'ssim': calculate_ssim(pred_dn, target_dn),\n",
        "        'csi': calculate_csi(pred_dn, target_dn),\n",
        "        'fss': calculate_fss(pred_dn, target_dn)\n",
        "    }\n",
        "\n",
        "# --- MODEL EVALUATION CLASS ---\n",
        "class ModelEvaluator:\n",
        "    def __init__(self, models_dir, data_dir, output_dir):\n",
        "        self.models_dir = Path(models_dir)\n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Load test dataset\n",
        "        self.test_dataset = MultiVariableARDataset(data_dir, 'test')\n",
        "        self.test_loader = DataLoader(self.test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "        # Load normalization stats\n",
        "        self.stats = joblib.load(data_dir / 'normalization_stats_multi_variable.joblib')\n",
        "\n",
        "        print(f\"üìä Test dataset: {len(self.test_dataset)} samples\")\n",
        "        print(f\"üîß Using device: {self.device}\")\n",
        "\n",
        "    def create_model_by_config(self, model_config):\n",
        "        \"\"\"Create model based on configuration.\"\"\"\n",
        "        model_type = model_config.get('type', 'original')\n",
        "        input_channels = model_config.get('input_channels', 5)\n",
        "\n",
        "        if model_type == 'original' or model_type == 'multivariable':\n",
        "            return MultiVariableGenerator(input_channels=input_channels)\n",
        "        elif model_type == 'resnet':\n",
        "            return ResNetUNet(input_channels=input_channels)\n",
        "        elif model_type == 'attention':\n",
        "            return AttentionUNet(input_channels=input_channels)\n",
        "        elif model_type == 'lightweight':\n",
        "            return LightweightCNN(input_channels=input_channels)\n",
        "        elif model_type == 'flexible':\n",
        "            return FlexibleGenerator(input_channels=input_channels)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown model type: {model_type}\")\n",
        "\n",
        "    def find_all_models(self):\n",
        "        \"\"\"Find all trained model files.\"\"\"\n",
        "        models = []\n",
        "\n",
        "        # Architecture comparison models\n",
        "        arch_dir = self.models_dir / 'architecture_comparison'\n",
        "        if arch_dir.exists():\n",
        "            for model_file in arch_dir.glob('*_final.pt'):\n",
        "                model_name = model_file.stem.replace('_final', '')\n",
        "                models.append({\n",
        "                    'name': f'arch_{model_name}',\n",
        "                    'path': model_file,\n",
        "                    'category': 'architecture',\n",
        "                    'description': f'Architecture: {model_name}',\n",
        "                    'type': model_name.replace('_unet', '').replace('_cnn', ''),\n",
        "                    'input_channels': 5\n",
        "                })\n",
        "\n",
        "        # Ablation study models\n",
        "        ablation_dir = self.models_dir / 'ablation_study'\n",
        "        if ablation_dir.exists():\n",
        "            for model_file in ablation_dir.glob('*_final.pt'):\n",
        "                model_name = model_file.stem.replace('_final', '')\n",
        "\n",
        "                # Determine input channels from model name\n",
        "                if 'single_' in model_name:\n",
        "                    input_channels = 1\n",
        "                elif 'pair_' in model_name:\n",
        "                    input_channels = 2\n",
        "                elif 'triplet_' in model_name:\n",
        "                    input_channels = 3\n",
        "                elif 'remove_' in model_name:\n",
        "                    input_channels = 4\n",
        "                else:\n",
        "                    input_channels = 5\n",
        "\n",
        "                models.append({\n",
        "                    'name': model_name,\n",
        "                    'path': model_file,\n",
        "                    'category': 'ablation',\n",
        "                    'description': f'Variables: {model_name}',\n",
        "                    'type': 'flexible',\n",
        "                    'input_channels': input_channels\n",
        "                })\n",
        "\n",
        "        # No GAN model\n",
        "        no_gan_dir = self.models_dir / 'no_gan_baseline'\n",
        "        if no_gan_dir.exists():\n",
        "            for i in range(5):\n",
        "                no_gan_file = no_gan_dir / f'no_gan_baseline_epoch_{(i+1)*5}.pt'\n",
        "                if no_gan_file.exists():\n",
        "                  models.append({\n",
        "                      'name': f'no_gan_baseline_epoch_{(i+1)*5}',\n",
        "                      'path': no_gan_file,\n",
        "                      'category': 'baseline',\n",
        "                      'description': f'No GAN Baseline {(i+1)*5}',\n",
        "                      'type': 'multivariable',\n",
        "                      'input_channels': 5\n",
        "                  })\n",
        "\n",
        "        # Fair baseline\n",
        "        baseline_dir = self.models_dir / 'fair_baseline_scratch'\n",
        "        if baseline_dir.exists():\n",
        "            baseline_file = baseline_dir / 'fair_baseline_final_model.pt'\n",
        "            if baseline_file.exists():\n",
        "                models.append({\n",
        "                    'name': 'fair_baseline',\n",
        "                    'path': baseline_file,\n",
        "                    'category': 'baseline',\n",
        "                    'description': 'Fair Baseline (From Scratch)',\n",
        "                    'type': 'multivariable',\n",
        "                    'input_channels': 5\n",
        "                })\n",
        "\n",
        "        print(f\"üîç Found {len(models)} trained models:\")\n",
        "        for model in models:\n",
        "            print(f\"   - {model['name']}: {model['description']}\")\n",
        "\n",
        "        # transfer learning models\n",
        "        transfer_dir = Path('/content/drive/MyDrive/AR_Downscaling/model_output_final_multi_variable')\n",
        "        if transfer_dir.exists():\n",
        "            for i in range(5):\n",
        "                transfer_file = transfer_dir / f'final_multi_var_gan_epoch_{(i+1)*5}.pt'\n",
        "                if transfer_file.exists():\n",
        "                    models.append({\n",
        "                        'name': 'transfer_learning_gan',\n",
        "                        'path': transfer_file,\n",
        "                        'category': 'transfer_learning',\n",
        "                        'description': f'Transfer Learning GAN {(i+1)*5}',\n",
        "                        'type': 'multivariable',\n",
        "                        'input_channels': 5\n",
        "                    })\n",
        "\n",
        "        return models\n",
        "\n",
        "    def load_model(self, model_config):\n",
        "        \"\"\"Load a trained model.\"\"\"\n",
        "        try:\n",
        "            # Load checkpoint\n",
        "            checkpoint = torch.load(model_config['path'], map_location=self.device, weights_only=False)\n",
        "\n",
        "            # Create model\n",
        "            model = self.create_model_by_config(model_config)\n",
        "\n",
        "            # Load state dict\n",
        "            if 'generator_state_dict' in checkpoint:\n",
        "                model.load_state_dict(checkpoint['generator_state_dict'])\n",
        "            elif 'model_state_dict' in checkpoint:\n",
        "                model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            else:\n",
        "                model.load_state_dict(checkpoint)\n",
        "\n",
        "            model.to(self.device)\n",
        "            model.eval()\n",
        "\n",
        "            return model, True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Failed to load {model_config['name']}: {e}\")\n",
        "            return None, False\n",
        "\n",
        "    def evaluate_model(self, model, model_config):\n",
        "        \"\"\"Evaluate a single model on test set.\"\"\"\n",
        "        print(f\"üéØ Evaluating {model_config['name']}...\")\n",
        "\n",
        "        # Determine if we need flexible dataset\n",
        "        if model_config['input_channels'] < 5:\n",
        "            # Need to determine which variables this model uses\n",
        "            # For now, use all variables and let the model handle it\n",
        "            # In practice, you'd need to store variable info with the model\n",
        "            test_loader = self.test_loader  # Use default 5-variable loader\n",
        "        else:\n",
        "            test_loader = self.test_loader\n",
        "\n",
        "        all_metrics = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for predictor, target in tqdm(test_loader, desc=f\"Evaluating {model_config['name']}\"):\n",
        "                predictor = predictor.to(self.device)\n",
        "                target = target.cpu().numpy().squeeze()\n",
        "\n",
        "                # Handle variable subset for ablation models\n",
        "                if model_config['input_channels'] < 5:\n",
        "                    # For ablation models, we need the right subset\n",
        "                    # This is a simplified approach - in practice you'd store this info\n",
        "                    predictor = predictor[:, :model_config['input_channels']]\n",
        "\n",
        "                # Generate prediction\n",
        "                try:\n",
        "                    prediction = model(predictor).cpu().numpy().squeeze()\n",
        "\n",
        "                    # Calculate metrics\n",
        "                    metrics = calculate_all_metrics(prediction, target, self.stats)\n",
        "                    all_metrics.append(metrics)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error in prediction for {model_config['name']}: {e}\")\n",
        "                    continue\n",
        "\n",
        "        if not all_metrics:\n",
        "            return None\n",
        "\n",
        "        # Calculate summary statistics\n",
        "        summary_metrics = {}\n",
        "        for metric_name in all_metrics[0].keys():\n",
        "            values = [m[metric_name] for m in all_metrics if not np.isnan(m[metric_name])]\n",
        "            if values:\n",
        "                summary_metrics[metric_name] = {\n",
        "                    'mean': np.mean(values),\n",
        "                    'std': np.std(values),\n",
        "                    'median': np.median(values),\n",
        "                    'min': np.min(values),\n",
        "                    'max': np.max(values),\n",
        "                    'count': len(values)\n",
        "                }\n",
        "\n",
        "        return summary_metrics\n",
        "\n",
        "    def evaluate_all_models(self):\n",
        "        \"\"\"Evaluate all found models.\"\"\"\n",
        "        models = self.find_all_models()\n",
        "        results = []\n",
        "\n",
        "        for model_config in models:\n",
        "            model, success = self.load_model(model_config)\n",
        "\n",
        "            if not success:\n",
        "                results.append({\n",
        "                    'name': model_config['name'],\n",
        "                    'category': model_config['category'],\n",
        "                    'description': model_config['description'],\n",
        "                    'status': 'failed_to_load',\n",
        "                    'input_channels': model_config['input_channels']\n",
        "                })\n",
        "                continue\n",
        "\n",
        "            metrics = self.evaluate_model(model, model_config)\n",
        "\n",
        "            if metrics is None:\n",
        "                results.append({\n",
        "                    'name': model_config['name'],\n",
        "                    'category': model_config['category'],\n",
        "                    'description': model_config['description'],\n",
        "                    'status': 'failed_evaluation',\n",
        "                    'input_channels': model_config['input_channels']\n",
        "                })\n",
        "                continue\n",
        "\n",
        "            # Add model info to results\n",
        "            result = {\n",
        "                'name': model_config['name'],\n",
        "                'category': model_config['category'],\n",
        "                'description': model_config['description'],\n",
        "                'status': 'success',\n",
        "                'input_channels': model_config['input_channels'],\n",
        "                **{f\"{metric_name}_{stat}\": value for metric_name, stats in metrics.items()\n",
        "                   for stat, value in stats.items()}\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "            print(f\"‚úÖ {model_config['name']} completed\")\n",
        "            print(f\"   RMSE: {metrics['rmse']['mean']:.3f} ¬± {metrics['rmse']['std']:.3f}\")\n",
        "            print(f\"   CSI: {metrics['csi']['mean']:.3f} ¬± {metrics['csi']['std']:.3f}\")\n",
        "            print(f\"   FSS: {metrics['fss']['mean']:.3f} ¬± {metrics['fss']['std']:.3f}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def generate_comparison_report(self, results):\n",
        "        \"\"\"Generate comprehensive comparison report.\"\"\"\n",
        "        # Convert to DataFrame\n",
        "        df = pd.DataFrame(results)\n",
        "        successful_df = df[df['status'] == 'success'].copy()\n",
        "\n",
        "        if len(successful_df) == 0:\n",
        "            print(\"‚ùå No successful evaluations to compare\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\nüìä Successfully evaluated {len(successful_df)} models\")\n",
        "\n",
        "        # Key metrics for comparison\n",
        "        key_metrics = ['rmse_mean', 'mae_mean', 'r2_mean', 'ssim_mean', 'csi_mean', 'fss_mean']\n",
        "\n",
        "        # Sort by CSI (Critical Success Index) - higher is better\n",
        "        if 'csi_mean' in successful_df.columns:\n",
        "            successful_df_sorted = successful_df.sort_values('csi_mean', ascending=False)\n",
        "        else:\n",
        "            successful_df_sorted = successful_df.sort_values('rmse_mean', ascending=True)\n",
        "\n",
        "        # Generate ranking table\n",
        "        print(\"\\nüèÜ Model Performance Ranking (by CSI):\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        ranking_data = []\n",
        "        for i, (_, row) in enumerate(successful_df_sorted.iterrows()):\n",
        "            ranking_data.append({\n",
        "                'Rank': i + 1,\n",
        "                'Model': row['name'],\n",
        "                'Category': row['category'],\n",
        "                'Description': row['description'],\n",
        "                'Channels': row['input_channels'],\n",
        "                'RMSE': f\"{row.get('rmse_mean', 0):.3f} ¬± {row.get('rmse_std', 0):.3f}\",\n",
        "                'CSI': f\"{row.get('csi_mean', 0):.3f} ¬± {row.get('csi_std', 0):.3f}\",\n",
        "                'FSS': f\"{row.get('fss_mean', 0):.3f} ¬± {row.get('fss_std', 0):.3f}\",\n",
        "                'SSIM': f\"{row.get('ssim_mean', 0):.3f} ¬± {row.get('ssim_std', 0):.3f}\"\n",
        "            })\n",
        "\n",
        "        ranking_df = pd.DataFrame(ranking_data)\n",
        "        print(ranking_df.to_string(index=False))\n",
        "\n",
        "        # Save detailed results\n",
        "        successful_df.to_csv(self.output_dir / 'detailed_test_results.csv', index=False)\n",
        "        ranking_df.to_csv(self.output_dir / 'model_ranking.csv', index=False)\n",
        "\n",
        "        # Generate analysis by category\n",
        "        self.analyze_by_category(successful_df)\n",
        "\n",
        "        # Generate visualizations\n",
        "        self.create_visualizations(successful_df)\n",
        "\n",
        "        print(f\"\\nüíæ Results saved to {self.output_dir}\")\n",
        "\n",
        "    def analyze_by_category(self, df):\n",
        "        \"\"\"Analyze results by model category.\"\"\"\n",
        "        print(f\"\\nüìà Analysis by Category:\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        categories = df['category'].unique()\n",
        "\n",
        "        for category in categories:\n",
        "            cat_df = df[df['category'] == category]\n",
        "            print(f\"\\n{category.upper()} Models ({len(cat_df)} models):\")\n",
        "\n",
        "            if 'csi_mean' in cat_df.columns:\n",
        "                best_model = cat_df.loc[cat_df['csi_mean'].idxmax()]\n",
        "                print(f\"  Best: {best_model['name']} (CSI: {best_model['csi_mean']:.3f})\")\n",
        "\n",
        "                avg_csi = cat_df['csi_mean'].mean()\n",
        "                print(f\"  Average CSI: {avg_csi:.3f}\")\n",
        "\n",
        "            if 'rmse_mean' in cat_df.columns:\n",
        "                avg_rmse = cat_df['rmse_mean'].mean()\n",
        "                print(f\"  Average RMSE: {avg_rmse:.3f}\")\n",
        "\n",
        "    def create_visualizations(self, df):\n",
        "        \"\"\"Create comparison visualizations.\"\"\"\n",
        "        # Set up the plotting style\n",
        "        plt.style.use('default')\n",
        "        sns.set_palette(\"husl\")\n",
        "\n",
        "        # Create a comprehensive comparison plot\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "        fig.suptitle('Model Performance Comparison on Test Set', fontsize=16, fontweight='bold')\n",
        "\n",
        "        # Plot 1: CSI comparison\n",
        "        if 'csi_mean' in df.columns:\n",
        "            df_sorted = df.sort_values('csi_mean', ascending=True)\n",
        "            axes[0, 0].barh(range(len(df_sorted)), df_sorted['csi_mean'],\n",
        "                           xerr=df_sorted['csi_std'], capsize=3)\n",
        "            axes[0, 0].set_yticks(range(len(df_sorted)))\n",
        "            axes[0, 0].set_yticklabels(df_sorted['name'], fontsize=8)\n",
        "            axes[0, 0].set_xlabel('Critical Success Index (CSI)')\n",
        "            axes[0, 0].set_title('Critical Success Index (Higher = Better)')\n",
        "            axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot 2: RMSE comparison\n",
        "        if 'rmse_mean' in df.columns:\n",
        "            df_sorted = df.sort_values('rmse_mean', ascending=True)\n",
        "            axes[0, 1].barh(range(len(df_sorted)), df_sorted['rmse_mean'],\n",
        "                           xerr=df_sorted['rmse_std'], capsize=3)\n",
        "            axes[0, 1].set_yticks(range(len(df_sorted)))\n",
        "            axes[0, 1].set_yticklabels(df_sorted['name'], fontsize=8)\n",
        "            axes[0, 1].set_xlabel('Root Mean Square Error (RMSE)')\n",
        "            axes[0, 1].set_title('RMSE (Lower = Better)')\n",
        "            axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot 3: FSS comparison\n",
        "        if 'fss_mean' in df.columns:\n",
        "            df_sorted = df.sort_values('fss_mean', ascending=True)\n",
        "            axes[1, 0].barh(range(len(df_sorted)), df_sorted['fss_mean'],\n",
        "                           xerr=df_sorted['fss_std'], capsize=3)\n",
        "            axes[1, 0].set_yticks(range(len(df_sorted)))\n",
        "            axes[1, 0].set_yticklabels(df_sorted['name'], fontsize=8)\n",
        "            axes[1, 0].set_xlabel('Fractions Skill Score (FSS)')\n",
        "            axes[1, 0].set_title('FSS (Higher = Better)')\n",
        "            axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot 4: Performance vs Complexity\n",
        "        if 'csi_mean' in df.columns and 'input_channels' in df.columns:\n",
        "            scatter = axes[1, 1].scatter(df['input_channels'], df['csi_mean'],\n",
        "                                       s=100, alpha=0.7, c=df.index)\n",
        "            axes[1, 1].set_xlabel('Number of Input Channels')\n",
        "            axes[1, 1].set_ylabel('Critical Success Index (CSI)')\n",
        "            axes[1, 1].set_title('Performance vs Model Complexity')\n",
        "            axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "            # Add labels for points\n",
        "            for i, row in df.iterrows():\n",
        "                axes[1, 1].annotate(row['name'][:10],\n",
        "                                   (row['input_channels'], row['csi_mean']),\n",
        "                                   xytext=(5, 5), textcoords='offset points',\n",
        "                                   fontsize=6, alpha=0.8)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(self.output_dir / 'model_comparison_plots.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        # Create category-wise comparison\n",
        "        self.create_category_plots(df)\n",
        "\n",
        "    def create_category_plots(self, df):\n",
        "        \"\"\"Create category-wise comparison plots.\"\"\"\n",
        "        categories = df['category'].unique()\n",
        "\n",
        "        if len(categories) > 1:\n",
        "            fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "            category_data = []\n",
        "            for category in categories:\n",
        "                cat_df = df[df['category'] == category]\n",
        "                if 'csi_mean' in cat_df.columns:\n",
        "                    category_data.append(cat_df['csi_mean'].values)\n",
        "\n",
        "            if category_data:\n",
        "                ax.boxplot(category_data, labels=categories)\n",
        "                ax.set_ylabel('Critical Success Index (CSI)')\n",
        "                ax.set_title('Performance Distribution by Model Category')\n",
        "                ax.grid(True, alpha=0.3)\n",
        "\n",
        "                plt.xticks(rotation=45, ha='right')\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(self.output_dir / 'category_comparison.png', dpi=300, bbox_inches='tight')\n",
        "                plt.close()\n",
        "\n",
        "# --- MAIN EXECUTION ---\n",
        "def main():\n",
        "    print(\"üéØ Starting Comprehensive Test Set Evaluation\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    evaluator = ModelEvaluator(\n",
        "        models_dir=MODELS_DIR,\n",
        "        data_dir=DATA_DIR,\n",
        "        output_dir=OUTPUT_DIR\n",
        "    )\n",
        "\n",
        "    # Run evaluation on all models\n",
        "    results = evaluator.evaluate_all_models()\n",
        "\n",
        "    # Generate comprehensive report\n",
        "    evaluator.generate_comparison_report(results)\n",
        "\n",
        "    print(\"\\nüéâ Comprehensive evaluation completed!\")\n",
        "    print(f\"üìä Results and visualizations saved to: {OUTPUT_DIR}\")\n",
        "\n",
        "    # Generate final summary\n",
        "    successful_results = [r for r in results if r['status'] == 'success']\n",
        "    if successful_results:\n",
        "        best_overall = max(successful_results, key=lambda x: x.get('csi_mean', 0))\n",
        "        print(f\"\\nüèÜ Best Overall Model: {best_overall['name']}\")\n",
        "        print(f\"   Description: {best_overall['description']}\")\n",
        "        print(f\"   CSI: {best_overall.get('csi_mean', 0):.3f}\")\n",
        "        print(f\"   RMSE: {best_overall.get('rmse_mean', 0):.3f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PUBLICATION-QUALITY VISUALIZATION SCRIPT (V14 - The Definitive Figure) ---\n",
        "# This definitive version incorporates professional meteorological visualization techniques\n",
        "# to finally do justice to the GAN's performance. It uses:\n",
        "#   1. A satellite-style colormap ('gist_gray_r') to make storms pop.\n",
        "#   2. Non-linear color scaling (PowerNorm) to reveal details in cold cloud tops.\n",
        "#   3. A magnified inset (\"microscope view\") for undeniable proof of sharpness.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as colors\n",
        "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.ndimage import uniform_filter, zoom, sobel\n",
        "from google.colab import drive\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "PROJECT_PATH = Path('/content/drive/My Drive/AR_Downscaling')\n",
        "DATA_DIR = PROJECT_PATH / 'final_dataset_multi_variable'\n",
        "MODELS_DIR = PROJECT_PATH / 'publication_experiments'\n",
        "OUTPUT_DIR = PROJECT_PATH / 'final_publication_figures'\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "DISASTER_DAYS = ['20230807_1200', '20230807_1800']\n",
        "TARGET_SHAPE = (256, 256)\n",
        "stats = joblib.load(DATA_DIR / 'normalization_stats_multi_variable.joblib')\n",
        "\n",
        "# --- HELPER & MODEL FUNCTIONS (No changes needed) ---\n",
        "# [All previous helper functions like load_and_crop_data, model architectures, etc., go here]\n",
        "# [For brevity, they are omitted, but they are the same as the V12/V13 script]\n",
        "def load_and_crop_data(file_path, target_shape=(256, 256)):\n",
        "    if not file_path.exists(): return None\n",
        "    data = np.load(file_path).astype(np.float32)\n",
        "    if data.ndim == 3: h, w = data.shape[1], data.shape[2]\n",
        "    else: h, w = data.shape\n",
        "    th, tw = target_shape\n",
        "    if h != th or w != tw:\n",
        "        start_h = max(0, (h - th) // 2); start_w = max(0, (w - tw) // 2)\n",
        "        if data.ndim == 3: cropped_data = data[:, start_h:start_h + th, start_w:start_w + tw]\n",
        "        else: cropped_data = data[start_h:start_h + th, start_w:start_w + tw]\n",
        "        if cropped_data.shape[-2:] != target_shape:\n",
        "            if cropped_data.ndim == 3:\n",
        "                padded_data = np.zeros((data.shape[0], *target_shape), dtype=np.float32)\n",
        "                padded_data[:, :cropped_data.shape[1], :cropped_data.shape[2]] = cropped_data\n",
        "            else:\n",
        "                padded_data = np.zeros(target_shape, dtype=np.float32)\n",
        "                padded_data[:cropped_data.shape[0], :cropped_data.shape[1]] = cropped_data\n",
        "            return padded_data\n",
        "        return cropped_data\n",
        "    return data\n",
        "class SimplifiedAttention(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.channel_att = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Conv2d(channels, channels // 16, 1), nn.ReLU(inplace=True), nn.Conv2d(channels // 16, channels, 1), nn.Sigmoid())\n",
        "        self.spatial_att = nn.Sequential(nn.Conv2d(channels, 1, 7, padding=3), nn.Sigmoid())\n",
        "    def forward(self, x):\n",
        "        ch_att = self.channel_att(x); x = x * ch_att; sp_att = self.spatial_att(x); x = x * sp_att\n",
        "        return x\n",
        "class MultiVariableGenerator(nn.Module):\n",
        "    def __init__(self, input_channels=5, base_channels=64, depth=4, use_attention=True):\n",
        "        super().__init__()\n",
        "        self.use_attention, self.depth = use_attention, depth\n",
        "        channels = [base_channels * min(2**i, 8) for i in range(depth)]\n",
        "        self.encoders, self.downsamplers = nn.ModuleList(), nn.ModuleList()\n",
        "        in_ch = input_channels\n",
        "        for i, out_ch in enumerate(channels):\n",
        "            self.encoders.append(self._conv_block(in_ch, out_ch))\n",
        "            if i < len(channels) - 1: self.downsamplers.append(nn.Conv2d(out_ch, out_ch, 3, stride=2, padding=1))\n",
        "            in_ch = out_ch\n",
        "        bottleneck_ch = channels[-1]\n",
        "        self.bottleneck = self._conv_block(channels[-1], bottleneck_ch)\n",
        "        if self.use_attention: self.attention = SimplifiedAttention(bottleneck_ch)\n",
        "        self.upsamplers, self.decoders = nn.ModuleList(), nn.ModuleList()\n",
        "        for i in range(depth-1, -1, -1):\n",
        "            in_ch = bottleneck_ch if i == depth-1 else channels[i+1]\n",
        "            out_ch = channels[i]\n",
        "            self.upsamplers.append(nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2))\n",
        "            self.decoders.append(self._conv_block(out_ch * 2, out_ch))\n",
        "        self.final_conv = nn.Sequential(nn.Conv2d(channels[0], 1, 1), nn.Tanh())\n",
        "    def _conv_block(self, in_ch, out_ch):\n",
        "        return nn.Sequential(nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False), nn.BatchNorm2d(out_ch), nn.LeakyReLU(0.2, inplace=True))\n",
        "    def forward(self, x):\n",
        "        skips = []\n",
        "        for i in range(len(self.encoders)):\n",
        "            x = self.encoders[i](x); skips.append(x)\n",
        "            if i < len(self.downsamplers): x = self.downsamplers[i](x)\n",
        "        x = self.bottleneck(x)\n",
        "        if self.use_attention: x = self.attention(x)\n",
        "        for i, (up, dec) in enumerate(zip(self.upsamplers, self.decoders)):\n",
        "            x = up(x); skip = skips[len(skips) - 1 - i]\n",
        "            if x.shape[-2:] != skip.shape[-2:]: x = F.interpolate(x, size=skip.shape[-2:], mode='bilinear', align_corners=False)\n",
        "            x = torch.cat([x, skip], dim=1); x = dec(x)\n",
        "        return self.final_conv(x)\n",
        "def denormalize(data, is_target=True):\n",
        "    if is_target: return data * (stats['target_std'] + 1e-8) + stats['target_mean']\n",
        "    else:\n",
        "        mean = stats['predictor_mean'][:, None, None]; std = stats['predictor_std'][:, None, None]\n",
        "        return data * (std + 1e-8) + mean\n",
        "def load_neural_model(model_path, model_class, device):\n",
        "    if not model_path.exists(): return None\n",
        "    print(f\"   Loading {model_path.name}...\")\n",
        "    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
        "    model = model_class(input_channels=5)\n",
        "    state_dict_key = 'generator_state_dict' if 'generator_state_dict' in checkpoint else 'model_state_dict'\n",
        "    model.load_state_dict(checkpoint[state_dict_key])\n",
        "    model.to(device); model.eval(); return model\n",
        "def predict_neural_model(model, predictor_data, device):\n",
        "    with torch.no_grad():\n",
        "        predictor_norm = (predictor_data - stats['predictor_mean'][:, None, None]) / (stats['predictor_std'][:, None, None] + 1e-8)\n",
        "        predictor_tensor = torch.from_numpy(predictor_norm).unsqueeze(0).to(device)\n",
        "        prediction_tensor = model(predictor_tensor)\n",
        "        prediction_norm = prediction_tensor.cpu().numpy().squeeze()\n",
        "        return denormalize(prediction_norm, is_target=True)\n",
        "def calculate_csi(pred, target, threshold=220.0):\n",
        "    pred_event = pred <= threshold; target_event = target <= threshold\n",
        "    hits = np.sum(pred_event & target_event)\n",
        "    misses = np.sum(~pred_event & target_event)\n",
        "    false_alarms = np.sum(pred_event & ~target_event)\n",
        "    return hits / (hits + misses + false_alarms) if (hits + misses + false_alarms) > 0 else 0.0\n",
        "def extract_multivar_features_for_rf(predictor_norm, window_size=5):\n",
        "    num_channels, h, w = predictor_norm.shape\n",
        "    num_features = num_channels * 3\n",
        "    X_pixel_major = predictor_norm.transpose(1, 2, 0).reshape(h * w, num_channels)\n",
        "    features = np.zeros((h * w, num_features), dtype=np.float32)\n",
        "    features[:, 0:num_channels] = X_pixel_major\n",
        "    for c in range(num_channels):\n",
        "        local_mean = uniform_filter(predictor_norm[c], size=window_size)\n",
        "        local_sq_mean = uniform_filter(predictor_norm[c]**2, size=window_size)\n",
        "        local_var = local_sq_mean - local_mean**2\n",
        "        local_std = np.sqrt(np.maximum(local_var, 0))\n",
        "        features[:, num_channels + c] = local_mean.flatten()\n",
        "        features[:, (2 * num_channels) + c] = local_std.flatten()\n",
        "    return features\n",
        "\n",
        "# --- THE DEFINITIVE VISUALIZATION FUNCTION ---\n",
        "\n",
        "def create_definitive_figure(timestamp, ground_truth, predictions, metrics):\n",
        "    \"\"\"\n",
        "    Creates the final, definitive figure with a professional satellite colormap,\n",
        "    non-linear scaling, and a magnified inset to prove the GAN's sharpness.\n",
        "    \"\"\"\n",
        "    model_order = ['Strong_RF_Baseline', 'Transfer_Learning_GAN']\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(21, 7), facecolor='white')\n",
        "    plt.style.use('default')\n",
        "    fig.suptitle(f'Model Comparison for Event: {timestamp}', fontsize=24, fontweight='bold')\n",
        "\n",
        "    # --- KEY VISUALIZATION IMPROVEMENTS ---\n",
        "    # 1. Use a professional, reversed grayscale colormap\n",
        "    TBB_CMAP = 'gist_gray_r'\n",
        "    # 2. Use a non-linear color scale (PowerNorm) to emphasize cold cloud tops\n",
        "    TBB_NORM = colors.PowerNorm(gamma=0.5, vmin=190, vmax=310)\n",
        "\n",
        "    # --- Data Preparation ---\n",
        "    rf_pred = predictions['Strong_RF_Baseline']\n",
        "    gan_pred = predictions['Transfer_Learning_GAN']\n",
        "\n",
        "    # --- Define the zoom area for the inset (e.g., a 64x64 box) ---\n",
        "    # This can be set manually or algorithmically\n",
        "    ZOOM_X, ZOOM_Y, ZOOM_SIZE = 120, 80, 64\n",
        "\n",
        "    # --- Column 1: Ground Truth ---\n",
        "    im_gt = axes[0].imshow(ground_truth, cmap=TBB_CMAP, norm=TBB_NORM)\n",
        "    axes[0].set_title('A) Ground Truth (TBB)', fontsize=18, fontweight='bold')\n",
        "    axes[0].add_patch(Rectangle((ZOOM_X, ZOOM_Y), ZOOM_SIZE, ZOOM_SIZE, fill=False, edgecolor='cyan', lw=2))\n",
        "    axins_gt = inset_axes(axes[0], width=\"40%\", height=\"40%\", loc='lower right')\n",
        "    axins_gt.imshow(ground_truth[ZOOM_Y:ZOOM_Y+ZOOM_SIZE, ZOOM_X:ZOOM_X+ZOOM_SIZE],\n",
        "                    cmap=TBB_CMAP, norm=TBB_NORM, origin=\"lower\")\n",
        "    axins_gt.set_xticks([]); axins_gt.set_yticks([])\n",
        "    mark_inset(axes[0], axins_gt, loc1=1, loc2=3, fc=\"none\", ec=\"cyan\", lw=1)\n",
        "\n",
        "    # --- Column 2: Strong RF Baseline ---\n",
        "    axes[1].imshow(rf_pred, cmap=TBB_CMAP, norm=TBB_NORM)\n",
        "    axes[1].set_title(f'B) RF Baseline (CSI: {metrics[\"Strong_RF_Baseline\"][\"csi\"]:.3f})', fontsize=18, fontweight='bold')\n",
        "    axes[1].add_patch(Rectangle((ZOOM_X, ZOOM_Y), ZOOM_SIZE, ZOOM_SIZE, fill=False, edgecolor='red', lw=2))\n",
        "    axins_rf = inset_axes(axes[1], width=\"40%\", height=\"40%\", loc='lower right')\n",
        "    axins_rf.imshow(rf_pred[ZOOM_Y:ZOOM_Y+ZOOM_SIZE, ZOOM_X:ZOOM_X+ZOOM_SIZE],\n",
        "                    cmap=TBB_CMAP, norm=TBB_NORM, origin=\"lower\")\n",
        "    axins_rf.set_xticks([]); axins_rf.set_yticks([])\n",
        "    mark_inset(axes[1], axins_rf, loc1=1, loc2=3, fc=\"none\", ec=\"red\", lw=1)\n",
        "\n",
        "    # --- Column 3: Transfer Learning GAN ---\n",
        "    axes[2].imshow(gan_pred, cmap=TBB_CMAP, norm=TBB_NORM)\n",
        "    axes[2].set_title(f'C) GAN Prediction (CSI: {metrics[\"Transfer_Learning_GAN\"][\"csi\"]:.3f})', fontsize=18, fontweight='bold')\n",
        "    axes[2].add_patch(Rectangle((ZOOM_X, ZOOM_Y), ZOOM_SIZE, ZOOM_SIZE, fill=False, edgecolor='lime', lw=2))\n",
        "    axins_gan = inset_axes(axes[2], width=\"40%\", height=\"40%\", loc='lower right')\n",
        "    axins_gan.imshow(gan_pred[ZOOM_Y:ZOOM_Y+ZOOM_SIZE, ZOOM_X:ZOOM_X+ZOOM_SIZE],\n",
        "                     cmap=TBB_CMAP, norm=TBB_NORM, origin=\"lower\")\n",
        "    axins_gan.set_xticks([]); axins_gan.set_yticks([])\n",
        "    mark_inset(axes[2], axins_gan, loc1=1, loc2=3, fc=\"none\", ec=\"lime\", lw=1)\n",
        "\n",
        "    # --- Final Touches ---\n",
        "    for ax in axes.flatten():\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "\n",
        "    fig.tight_layout(rect=[0, 0, 1, 0.93])\n",
        "    filename = f'definitive_figure_{timestamp}.png'\n",
        "    plt.savefig(OUTPUT_DIR / filename, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"   üìä Saved new Definitive Figure: {filename}\")\n",
        "\n",
        "# --- MAIN ANALYSIS ---\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    models_to_load = {\n",
        "        'Transfer_Learning_GAN': (MODELS_DIR.parent / 'model_output_final_multi_variable' / 'final_multi_var_gan_epoch_25.pt', MultiVariableGenerator),\n",
        "        'Strong_RF_Baseline': (MODELS_DIR / 'strong_baseline_rf' / 'strong_baseline_rf.joblib', None)\n",
        "    }\n",
        "    loaded_models = {}\n",
        "    for name, (path, model_class) in models_to_load.items():\n",
        "        if name == 'Strong_RF_Baseline':\n",
        "            if path.exists():\n",
        "                loaded_models[name] = joblib.load(path)\n",
        "                print(f\"   ‚úÖ Loaded {name}\")\n",
        "        else:\n",
        "            model = load_neural_model(path, model_class, device)\n",
        "            if model: loaded_models[name] = model\n",
        "\n",
        "    for timestamp in DISASTER_DAYS:\n",
        "        print(f\"\\nüåä Analyzing timestamp: {timestamp}\")\n",
        "        test_dir = DATA_DIR / 'test'\n",
        "        predictor_data = load_and_crop_data(test_dir / f'{timestamp}_predictor.npy')\n",
        "        ground_truth_norm = load_and_crop_data(test_dir / f'{timestamp}_target.npy')\n",
        "        if predictor_data is None or ground_truth_norm is None:\n",
        "            print(f\"   ‚ö†Ô∏è Data not found for {timestamp}, skipping.\"); continue\n",
        "\n",
        "        ground_truth = denormalize(ground_truth_norm, is_target=True)\n",
        "        predictions, metrics = {}, {}\n",
        "\n",
        "        for name in ['Strong_RF_Baseline', 'Transfer_Learning_GAN']:\n",
        "            if name not in loaded_models: continue\n",
        "            model = loaded_models[name]\n",
        "\n",
        "            if name == 'Strong_RF_Baseline':\n",
        "                predictor_norm = (predictor_data - stats['predictor_mean'][:, None, None]) / (stats['predictor_std'][:, None, None] + 1e-8)\n",
        "                features = extract_multivar_features_for_rf(predictor_norm)\n",
        "                pred_norm_flat = model.predict(features)\n",
        "                pred_norm = pred_norm_flat.reshape(TARGET_SHAPE)\n",
        "                prediction = denormalize(pred_norm, is_target=True)\n",
        "            else:\n",
        "                prediction = predict_neural_model(model, predictor_data, device)\n",
        "\n",
        "            predictions[name] = prediction\n",
        "            metrics[name] = {'csi': calculate_csi(prediction, ground_truth)}\n",
        "            print(f\"   ‚úÖ Generated prediction for {name}\")\n",
        "\n",
        "        if predictions:\n",
        "            create_definitive_figure(timestamp, ground_truth, predictions, metrics)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "JrR0jvOL0eJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03e4b52b-2973-46c0-a6d2-695ce0869e37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "   Loading final_multi_var_gan_epoch_25.pt...\n",
            "   ‚úÖ Loaded Strong_RF_Baseline\n",
            "\n",
            "üåä Analyzing timestamp: 20230807_1200\n",
            "   ‚úÖ Generated prediction for Strong_RF_Baseline\n",
            "   ‚úÖ Generated prediction for Transfer_Learning_GAN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   üìä Saved new Definitive Figure: definitive_figure_20230807_1200.png\n",
            "\n",
            "üåä Analyzing timestamp: 20230807_1800\n",
            "   ‚úÖ Generated prediction for Strong_RF_Baseline\n",
            "   ‚úÖ Generated prediction for Transfer_Learning_GAN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   üìä Saved new Definitive Figure: definitive_figure_20230807_1800.png\n"
          ]
        }
      ]
    }
  ]
}